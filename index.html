<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>twn29004&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="twn29004&#39;s Blog">
<meta property="og:url" content="http://twn29004.top/index.html">
<meta property="og:site_name" content="twn29004&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="twn29004">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="twn29004&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">twn29004&#39;s Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://twn29004.top"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-mmvirtualpioint" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/02/27/mmvirtualpioint/" class="article-date">
  <time datetime="2022-02-26T16:00:00.000Z" itemprop="datePublished">2022-02-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/02/27/mmvirtualpioint/">Multimodal Virtual Point 3D Detection论文解读</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202202271633038.png" alt="image-20220227163310970" /></p>
<p><a target="_blank" rel="noopener" href="https://github.com/tianweiy/MVP">代码链接</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2111.06881">paper链接</a></p>
<p><a href="https://twn29004.top/">个人博客</a></p>
<h2 id="问题">问题</h2>
<p>本文提出了一种针对二维和三维信息融合的方法以解决三维点云稀疏难以检测远处的目标的问题。</p>
<h2 id="解决方法">解决方法</h2>
<p>本文的主要步骤是首先对与点云对应的二维RGB图像进行语义分割。然后讲三维点云投影到二维RGB相机坐标内。仅考虑位于前景点实体分割中的点。根据位于前景实体区域内的点云生成虚拟点。其生成虚拟点的方法是在二维前景实体分割区域中进行随机采样<span class="math inline">\(K\)</span>个点，然后根据这<span class="math inline">\(K\)</span>个点周围的最近的几个原始点云的深度插值出虚拟点的深度，然后讲这些虚拟点反向投影回三维空间中，同时这些虚拟点包含实体分割中的类别信息。然后对含有虚拟点的点云使用3D backbone进行处理。</p>
<p>上述生成虚拟点的依据可能是对于属于同一个前景目标中的点，其前景深度不会相差很大，所以可以用其周围点的深度信息来对虚拟点的深度信息进行补全。从而到达缓解点云稀疏性的目的。</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202202271643878.png" alt="虚拟点生成图示" /></p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202202271703587.png" alt="虚拟点补全效果" /></p>
<h2 id="解决效果">解决效果</h2>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202202271643653.png" alt="image-20220227164351603" /></p>
<p>相比于baseline CenterPoint,从上述表格中可以看出，使用生成的修点确实能够在一定程度上提高模型的检测性能。此外，相比于同样采用分割结果来进行多模态融合的PointPainting, 该方法也获得了更好的性能。</p>
<h2 id="消融实验">消融实验</h2>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202202271645619.png" alt="image-20220227164547573" /></p>
<p>本文首先探究了不同的三维Backbone对于模型检测性能的影响。其中Split Voxelization表示的对于原始点和虚拟点采用不同的处理策略。从上述表的中可以看出，使用Split Voxelization对于模型实际的检测性能影响并不大。</p>
<p>此外，作者还探究了本文所提方法对不同距离的目标的检测性能的影响。</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202202271648920.png" alt="image-20220227164831873" /></p>
<p>从上述表格中可以看出，其中CenterPoint + Ours(w/o virtual)表示的是PointPainting方法。从表中可以看出，使用虚拟点对于距离较远的目标的检测性能提升明显。</p>
<p>此外，作者还研究了实体分割精度对于检测性能的影响。</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202202271650444.png" alt="image-20220227165055400" /></p>
<p>文中通过使用降低输入分辨率模拟实体分割精度下降的方法，从文中可以看出，本文所提方法对于实例分割的精度还是具有较高的鲁棒性。</p>
<p>此外，作者还在文中提到，其在实验过程中验证了本文中所使用的基于邻近点进行深度估计的精度，平均误差在0.33m左右，可见在同一前景目标中，这种基于临近点的深度估计精度还是比较高的。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://twn29004.top/2022/02/27/mmvirtualpioint/" data-id="cl2d63r8x001kmsxc0ewcgdwj" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Fusion/" rel="tag">Fusion</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2-17调研" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/02/26/2-17%E8%B0%83%E7%A0%94/" class="article-date">
  <time datetime="2022-02-26T00:49:09.966Z" itemprop="datePublished">2022-02-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2201.01427">论文连接</a>未录取论文arxiv上的</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202202181520005.png" alt="image-20220218152046931" /></p>
<p>现有的RGB-D的语义分割大都是分别处理深度信息和RGB信息，但是通常联合推理RGBD的颜色信息和几何信息能够取得更好的分割效果。因此，本文提出了一种针对RGBD数据语义分割的基于注意力的双监督编码器架构。本文的基础架构如下:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202202181525579.png" alt="image-20220218152510529" /></p>
<p>蓝色和灰色分别代表RGB数据和深度数据。在联合学习中，不同任务特定的编码器探索不同任务之间的相关性。这些方法都是以编码器特定的感受野固定比例执行多任务蒸馏。但是，这些任务的影响并不只固定在某一特定的比例。因此，传统的简单的聚合方式例如跳连接(skip connection)，多尺度特征融合对于语义分割这类复杂任务的作用非常有限。</p>
<p>因此本文设计了一种简单高效的的对称网络以高效的利用多尺度的跨模态信息。我们首先提出一种基于注意力的多模态融合模块来处理两分支解码器中的多级配对互补信息，用于融合来自RGB数据和深度数据的特征。同时为了能在编码过程中学习跨模态信息，本文提出了一种新的双分支解码结构，该结构主要用于由另一个任务引导分支监督的语义分割。这样的设计能够使得我们能够通过主分支末尾的ASPP模块合并多尺度上下文特征，其中ASPP模块中包含金字塔进度用于增强深度表示。该双分支解码器能够通过多任务蒸馏提高语义分割的性能，同时促进训练的融合，解决编解码器的不平衡问题。</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202202181545350.png" alt="image-20220218154512252" /></p>
<p>其主要流程是分别使用ResNet50处理RGB数据和深度数据，然后对返回的不同层级的特征使用AMF模块进行融合，其中主要采用通道注意力和空间注意力来进行融合，对于融合生成的特征采用双解码器的结构进行解码。</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202202181557365.png" alt="image-20220218155750295" /></p>
<p>双分支解码器的相似结构，其中前文提高的金字塔监督方式就是利用不同尺度的特征生成不同尺度的分割结果对该尺度的特征进行监督，以此来进一步解决梯度消失的问题，另一个分支重复第一个分支的操作，但是不适用金字塔监督方法，最终生成深度估计结果或者语义分割结果，并使用最终生成的加过来监督主分支中生成的结果。本文中在预训练阶段第二个分支生成的是深度信息，在微调阶段生成的是语义分割结果。最终的损失函数由三部分组成，金字塔监督部分，第二分支监督部分和与GT之间的损失。</p>
<p>修改</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://twn29004.top/2022/02/26/2-17%E8%B0%83%E7%A0%94/" data-id="cl2d63r700001msxcbe94a8jq" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Faster-RCNN" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/01/14/Faster-RCNN/" class="article-date">
  <time datetime="2022-01-13T16:00:00.000Z" itemprop="datePublished">2022-01-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5/">参考链接</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/01/14/Faster-RCNN/">Faster-RCNN论文解读</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/31426458">知乎-参考链接</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://twn29004.top/2022/01/14/Faster-RCNN/" data-id="cl2d63r83000imsxc4444dtje" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/2D-Object-Detection/" rel="tag">2D Object-Detection</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-3D_IoU_Net" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/01/13/3D_IoU_Net/" class="article-date">
  <time datetime="2022-01-12T16:00:00.000Z" itemprop="datePublished">2022-01-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/01/13/3D_IoU_Net/">3D IoU-Net论文解读</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201131930976.png" alt="image-20220113193045205" /></p>
<p><a href="">代码链接</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2004.04962">paper链接</a></p>
<p><a href="https://twn29004.top/">个人博客</a></p>
<h2 id="问题-test">问题 test</h2>
<p>本文首先说明了一个问题就是NMS是一个非常重要的去除预测结果中重复的后处理过程。一些工作已经发现在NMS中使用IOU来作为排序的标准能够取得更好的效果。这里作者还用一个实验证明了上述说法的正确性。</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201131939783.png" alt="image-20220113193941682" /></p>
<p>上表中的Ground truth IoU表示的是通过计算预测的边界框与基准值之间的IoU作为NMS中的分数的标准。从上表的结果可以看出，在使用IoU来知道NMS之后，模型的精度得到了非常大的提高。此外，之前的一些工作已经做出了使用预测IoU而不是预测class score来作为NMS的评分标准。大部分方法是通过增加一个IoU分支来直接简单的预测IoU，但是这些方法存在着两个问题:</p>
<ol type="1">
<li><p>直接增加一个IoU预测分支，而没有提取一些对于IoU预测很重要的特征。</p></li>
<li><p>另一个问题是IoU的预测存在着不对齐的问题。</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201131944113.png" alt="不对齐问题" /></p></li>
</ol>
<p>具体情况如上图所示，上述结果展示的是经过refine之后的IoU的分布和没有经过Refine的IoU的分布。在训练的时候，IoU预测分支是使用的proposal的特征和基准框之间IoU,但是在测试时候，这个预测值被当成了是预测的边界框与基准框之间的IoU.两者的IoU分布又不一致，这就带来了一定的不对齐问题。下面介绍作者针对上述两个问题提出的解决方案。</p>
<h2 id="解决方法">解决方法</h2>
<h3 id="没有相关特征的问题">没有相关特征的问题</h3>
<p>针对上述问题，作者通过提出两个模型来解决。这两个模型分别叫 Attentive Corner Aggregation(ACA), Corners Geometry Encoding(CGE)模块。作者使用这两个模型来提取预测IoU所需的特征。从名字可以看出，都是关于Corner的。下面分别介绍这两个模块的工作方式。</p>
<h4 id="aca模块">ACA模块</h4>
<p>首先介绍ACA模块，在介绍该模块之前，作者首先介绍了设计该模块的动机。</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201131955158.png" alt="image-20220113195532024" /></p>
<p>从上图中可以看出，不同角度观察到的目标的可视部分是一样的，这可能是不利于我们提取特征的，同时也不利于我们来提取对于预测IoU很重要的特征，因此作者设计了一下这个模块，按照作者的说法是这个模块可以在一定程度上减少因为观察的角度不同带来的提取特征的差异。</p>
<p>具体设计如下:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201131953095.png" alt="image-20220113195349003" /></p>
<p>在使用PoineNet2生成Proposal，以及生成逐点的语义特征之后，作者使用上述方法来聚合proposal中的点，以生成每个proposal的特征。与PointRCNN中相似，作者同样使用PointNet2来提取Proposal中的特征，区别在于，是叠加了<span class="math inline">\(K\)</span>个SA层之后，在第<span class="math inline">\(K+1\)</span>层，作者没有再使用FPS来采样点，而是使用proposal的八个角点来作为采样后的点，然后搜索位于这个八个角点半径<span class="math inline">\(r\)</span>以内的点，在使用PointNet来提取这些区域的特征，然后再在这些特征上应用注意力机制。具体的注意力机制如下图所示:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201132007475.png" alt="image-20220113200708349" /></p>
<p>就是分别在不同的角点以及不同的通道层面做一次注意力机制。然后最后的特征是这八个角点的特诊之和。</p>
<h4 id="cge模块">CGE模块</h4>
<p>这个模块提出的目的是为了利用proposal的几何特征。上面提取的我们可以理解为语义特征。这部分的结果也非常简单，就是将proposal的八个角点的世界坐标作为神经网络的输入，其具体结构如下:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201132011527.png" alt="image-20220113201130455" /></p>
<h3 id="关于iou预测不对齐的问题">关于IoU预测不对齐的问题</h3>
<p>这部分的设计也很简单。具体操作看下图。在进行一次IoU预测之后，将预测的边界框作为Proposal在输入Proposal模块中重复一下，这样IoU分支最终预测的就是refine后的box和基准狂之间的IoU,这样就解决了不对齐的问题。值得注意的是，在重复一次的时候，只有IoU分支改变，其余分支是不变的。不然又会带来不对齐的问题。</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201132012175.png" alt="image-20220113201245045" /></p>
<h2 id="解决效果">解决效果</h2>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201132016891.png" alt="image-20220113201627789" /></p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201132018766.png" alt="image-20220113201719983" /></p>
<p>这是本文在Kitti测试集上取得的效果，这个效果一般般吧。<strong>为什么有的模型在验证集和测试集上的差距很小，而有的很大。是方法设计的问题吗？</strong></p>
<h2 id="消融实验">消融实验</h2>
<h3 id="iou对齐是否有效">IoU对齐是否有效</h3>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201132022374.png" alt="image-20220113202239311" /></p>
<p>这里的baseline表示的是PointRCNN增加了一个IoU分支。Alignment中<span class="math inline">\(\times\)</span>表示的是没有将预测生成的bbox在送到网络中，<span class="math inline">\(\checkmark\)</span>表示的是重复了一次，此外，作者还做了一个关于置信度对齐的实验。其结果如下:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201132027264.png" alt="image-20220113202755167" /></p>
<p>从上述表格中可以看出，置信度对齐不仅没有带来效果提升，来带来了下降。作者在文中仅简单的将其解释为置信度不使用于对齐操作。<strong>这个解释有点牵强，置信度同样也是预测的proposal的特征得到的置信度啊。</strong></p>
<h3 id="iou相关特征模块有效性验证">IoU相关特征模块有效性验证</h3>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201132023022.png" alt="image-20220113202349938" /></p>
<p>ACA模块中一些操作的对比实验。</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201132033354.png" alt="image-20220113203340244" /></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://twn29004.top/2022/01/13/3D_IoU_Net/" data-id="cl2d63r790003msxc263ods0y" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/3D-Object-Detection/" rel="tag">3D Object Detection</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-YOLOF" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/01/12/YOLOF/" class="article-date">
  <time datetime="2022-01-11T16:00:00.000Z" itemprop="datePublished">2022-01-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/01/12/YOLOF/">YOLOF论文解读</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a target="_blank" rel="noopener" href="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201112109346.png">image-20220111210952738</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/megvii-model/YOLOF">代码链接</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2103.09460">paper链接</a></p>
<p><a href="https://twn29004.top/">个人博客</a></p>
<h2 id="问题">问题</h2>
<p>本文首先分析了FPN网络的必要性。并通过实验证明，FPN有效的原因并不是因为融合了不用尺度的特征，而是因为其采取的分治的处理方法。其实验结果如图所示:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201112117451.png" alt="image-20220111211722356" /></p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201112118331.png" alt="image-20220111211832232" /></p>
<p>其中MiMo(Multi-Input-Multi-Output)表示的是不同尺度的特征图作为输入，同时不同尺度的特征图对应多个输出，SiMo(Single-Input-Multi-Output)表示仅使用单个尺度的特征图作为输入，然后分别对特征图进行下采样或者上采样最后生成不同尺度的输出。其余的方法类似。从作者的实验结果可以看出，其中SiMo网络获得的性能和MiMo网络获得的性能非常相近，其差别&lt;1AP。这在一定程度上说明了FPN网络的成功并不是因为其融合了多尺度的特征，而是因为他分别处理了不同尺度的对象。同时也说明，一定尺度的特征图其实已经包含了丰富的不同尺度的上下文信息。</p>
<p>在了解了FPN网络成功的主要因素后，作者又分析到，虽然分治能够提高模型的检测性能，但是其在一定程度上带来了额外的计算开销，减慢了模型的检测速度。因此，作者还是使用SiSo结构的检测头。为了能够弥补SiSo结构和MiMo结构之间的性能差异，作者分析了SiSo结构性能差的原因。其主要是两方面的原因:</p>
<ol type="1">
<li><p>当尺度的特征图通常只有有限的感受野，感受野只能覆盖部分大小的目标，因此其检测性能较差。此外，使用标准卷积和空洞卷积来扩大网络的感受野也不能从根本上解决问题。因为该方法是在原来的基础上乘一个大于1的倍数，会使得网络的感受野整体扩大。具体可参考下图:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201112133186.png" alt="image-20220111213322098" /></p>
<p>上图中绿色的实心点表示的是检测目标所需的感受野的大小，从左到右一次增大。(a)展示了原始网络的感受野。(b)展示了使用标准卷积和空洞卷积后的感受野，从图中可以看出，虽然感受野有一定程度的扩大，但是整体右移了，对于一些小目标仍然难以处理。(c)为作者在本文中提出的基于残差的空洞卷积特征提取网络。</p></li>
<li><p>Positive anchor不平衡的问题。从multi-out到single-out, 网络中的anchor的数量大幅下降，这就带来了anchor稀疏的问题，anchor稀疏带来了另一个问题就是就是anchor和GT匹配的问题。由于传统的GT和anchor通常是根据Max-IoU的策略来进行绑定的。这就导致大的GT通常比小的GT能够绑定更多的anchor，这使得网络倾向于关注大的GT，而忽略了小的GT。</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201112143166.png" alt="anchor-sparse" /></p>
<p>从上图中可以看出，Max-Iou表示的根据IoU来将anchor和GT绑定后的效果。large的GT绑定了非常多的anchor。ATSS是另一种分配策略。Top1则是只选择IoU最大的anchor。</p></li>
</ol>
<h2 id="解决方法">解决方法</h2>
<h3 id="单一特征图感受野有限的问题">单一特征图感受野有限的问题</h3>
<p>作者通过空洞卷积来解决感受野有限的问题。但是单纯的使用空洞卷积并不能从根本上解决问题，具体原因在上一节的1中已经分析了。因此作者引入了ResNet的残差结构。具体结构如下图所示:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201112153752.png" alt="image-20220111215339670" /></p>
<p>这里为什么作者使用相加来融合不同尺度的特征而不是使用拼接的方法？分析其原因作者的目的是在同一个位置能够获得不同感受野的特征。如果使用拼接的方法的话，相同的位置仍然只有一个感受野的特征，这不能满足作者在本工作中的需求。(在尝试的特征融合的时候，可以根据具体情况分析使用concat方法还是使用add的方法来进行融合)</p>
<h3 id="positive-anchor不平衡的问题">positive anchor不平衡的问题</h3>
<p>positive anchor的划分在目标检测中是一个非常重要的优化问题。在anchor-based的方法中,我们通常根据anchor和GT的IoU来确定anchor是否是positive的。当anchor与GT的IoU超过一个阈值时,我们就将该anchor确定为positive。这就导致大的GT通常回和大量的anchor具有超过阈值的IoU。这使得总的positice anchor中,对应的大的GT的anchor占大多数，这就使得网络倾向于优化大的GT。为了解决这个问题，作者提出了一种新的匹配策略，作者将其称为Uniform-Matching。</p>
<p>为了能够保证不同大小的GT都能匹配相同数目的anchor,作者并没有根据IoU来确定anchor是positive还是negative，而是选择距离GT最近的K个anchor作为posirtive的anchor。同时忽略IoU大于0.7的negative的anchor,忽略IoU小于0.15的positive的anchor。</p>
<p>此外，作者还发现在本工作中限制中心点在一定范围内偏移也是非常有效。作者限制所有anchor中心点的偏移应该小于32 pixels.</p>
<h2 id="解决效果">解决效果</h2>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201112219423.png" alt="image-20220111221947298" /></p>
<h2 id="消融实验">消融实验</h2>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201132051804.png" alt="image-20220113205148655" /></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://twn29004.top/2022/01/12/YOLOF/" data-id="cl2d63r8v001gmsxc07jh2lk6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/2D-Object-Detection/" rel="tag">2D Object Detection</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-GSPN" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/01/09/GSPN/" class="article-date">
  <time datetime="2022-01-08T16:00:00.000Z" itemprop="datePublished">2022-01-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/01/09/GSPN/">GSPN论文解读</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a target="_blank" rel="noopener" href="https://github.com/ericyi/GSPN">代码链接</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1812.03320">paper链接</a></p>
<p><a href="https://twn29004.top/">个人博客</a></p>
<h2 id="问题">问题</h2>
<p>目前的一些点云实体分割算法的一些工作是首先生成目标的近似几何估计，例如三维边界框，虽然这些估计很简单，但是由于大多数估计的生成缺乏对于目标几何信息的理解，导致这些生成的近似都是很满盲目的，其中要么包含很多个目标，要么仅包含部分目标，这大大影响了网络的实例分割的性能。除此之外，我们很难理解这些生成提议的网络对于三维几何信息理解的好坏。</p>
<p>为了能够更好的了解提出提议的网络对于三维几何信息的理解的好坏，本文作者提出了一种新的三维实体分割的方法。该方法在生成提议之前，首先重建这些目标。本文使用生成模型显示的生成自然目标的分布，并通过从目标对象的分布中采样生成提议。</p>
<p>该方法在三维的实体分割中比二维的更具有吸引力，原因是三维目标具有更多完成的三维几何形状，具有更好的物理尺度，这在一定程度上保证了我们能够获取三维目标的分布规律。</p>
<h2 id="解决方法">解决方法</h2>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201091935701.png" alt="image-20220109193523485" /></p>
<center>
GCPN网络结构
</center>
<p>GSPN网络将目标的提议问题看作是一个目标生成问题。其中原始的目标分布符合条件概率<span class="math inline">\(P_{\theta}(x|c)\)</span>，其中<span class="math inline">\(c\)</span>是点云<span class="math inline">\(P\)</span>和采样点集合<span class="math inline">\(s\)</span>的组合。输出的生成点云<span class="math inline">\(\tilde x\)</span>可以看作是在<span class="math inline">\(P\)</span>中包含<span class="math inline">\(s\)</span>的情况下对目标的近似。该方法可以使我们能够清楚的看到对象提案的样子，并了解网络是否真的理解了目标。</p>
<p>本文中将生成问题转化为了条件变分自编码机(Conditional Variational Autoencoders)，没有使用GAN的原因是GAN没有明确的模拟数据的分布，因此可能会带来模式崩塌问题(即生成器只生成<strong>少量</strong>真实样本)。</p>
<p>关于CVAE的说明可以参考<a target="_blank" rel="noopener" href="https://www.zhihu.com/answer/2257176201?type=video&amp;content_id=1450799967077752832">链接</a>,其基本思想就是将使用编码器将输入编码到一个隐空间，然后从隐空间中采样，再使用Decoder产生输出。</p>
<p>因此，proposal的生成可以分为两部分，<span class="math inline">\(P_{\theta}(z|C)\)</span>和<span class="math inline">\(P_{\theta}(x|z,C)\)</span>.首先预测在当前点云场景和采样的条件下，隐藏空间<span class="math inline">\(z\)</span>的分布。<span class="math inline">\(P_{\theta}(z|C)\)</span>，然后在前面生成的<span class="math inline">\(z\)</span>的分布上采样，输入到生成网络中生成proposal。</p>
<p>其中GSPN网络中主要分为四个主要的部分，分别是Center Prediction Network, Recognition Network，Prior Network和Generation Network。其中前三个主要是为CVAE中的Encoder服务。下面分别介绍这些自网络的作用:</p>
<ul>
<li>Center Prediction Network</li>
</ul>
<p>该部分网络的主要作用是通过提取采样点多尺度的特征，生成proposal的中心点的预测。然后使用预测的中心点对这些多尺度的区域进行归一化。调整这些区域。这部分的采用的标签为目标的几何中心点。</p>
<ul>
<li>Prior Network</li>
</ul>
<p>这部分网络的作用主要是用来计算<span class="math inline">\(P(z|C)\)</span>。即计算当前点云空间下，隐空间的分布。其使用的输入是经过Center Prediction网络归一化后的点云，其提取特征的步骤与Center Prediction部分基本相似，区别仅在输出的形式不太一样。这部分输出的是<span class="math inline">\(P(z|C)\)</span>的概率分布的参数。</p>
<p>这部分网络存在一个问题，就是这部分网络的输出到目前位置是没有标签的。因此我们需要构造一个这部分的标签，这部分的工作由另一个子网络来完成。</p>
<ul>
<li>Recognition Network</li>
</ul>
<p>这部分网络以真实的目标<span class="math inline">\(x\)</span>经过中心点归一化后输入，此外，还使用Prior Network中生成的语义特征作为输入，生成概率分布<span class="math inline">\(P_{\theta}(z|C,x)\)</span>。因此，网络优化的目标就是使得Prior Network和Recognition Network两个子网络生成的概率分布尽可能的近似。</p>
<ul>
<li>Generation Network</li>
</ul>
<p>在Prior Network生成在<span class="math inline">\(C\)</span>条件下关于<span class="math inline">\(z\)</span>的分布之后，从获得的分布中采样<span class="math inline">\(z\)</span>和Prior Network中生成的语义特征作为生成网络的输入，最终生成Proposal中所包含的点。</p>
<ul>
<li>Region-based PointNet</li>
</ul>
<p>为了能够更好的利用GSPN生成的proposal。作者提出了一个新的R-PointNet。其具体结构如下图所示:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201092034411.png" alt="image-20220109203442249" /></p>
<p>从上图中可以看出，首先对输入点云进行采样，然后使用PointNet++提取语义特征<span class="math inline">\(f_{sem}\)</span>，此外，还使用GSPN生成proposal中包含的虚拟点以及其提取的上下文特征<span class="math inline">\(f_{\hat c}\)</span>，生成的proposal经过RoI Generation网络，该网络会根据生成的proposal生成一个三维边界框。然后使用类似于Mask RCNN中的Point RoIAlign网络来提取RoI中的特征以进行下一步的分类，边界框回归和分割。</p>
<h2 id="解决效果">解决效果</h2>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201092047586.png" alt="image-20220109204728511" /></p>
<h2 id="消融实验">消融实验</h2>
<ol type="1">
<li><p>作者对比了本文提出的3D Proposal方法和其余两种BBox Reg方法和分割方法,其具体表现如下:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201092114536.png" alt="image-20220109211440451" /></p></li>
<li><p>此外，作者还对GSPN网络的结构进行了对比实验。</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201092115244.png" alt="image-20220109211551176" /></p>
<p>其中E-D表示的是使用传统的Encoder-Decoder结构，1-Context是指只是用一个维度的上下文信息，No Center Pred表示的是是否使用中心点预测网络。</p></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://twn29004.top/2022/01/09/GSPN/" data-id="cl2d63r86000kmsxc9hgp6xw5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Instance-Segment/" rel="tag">Instance Segment</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-pytorchwithcuda" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/01/09/pytorchwithcuda/" class="article-date">
  <time datetime="2022-01-08T16:00:00.000Z" itemprop="datePublished">2022-01-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%9F%A5%E8%AF%86%E5%88%86%E4%BA%AB/">知识分享</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/01/09/pytorchwithcuda/">Pytorch,CUDA联合编程</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="pytorch和cuda联合编程的基本步骤">Pytorch和CUDA联合编程的基本步骤</h1>
<p><a target="_blank" rel="noopener" href="https://www.w3cschool.cn/pytorch/pytorch-r9fw3btc.html">参考链接-w3school</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/wqwqqwqw1231/article/details/106902235">参考链接-CSDN</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/twn29004/PytorchAndCUDA">本文代码-github</a></p>
<h2 id="背景">背景</h2>
<p>目前PyTorch已经提供了丰富的接口可以直接调用，但是仍存在一些高度自定义的操作无法使用PyToch或者Python高效的完成，因此PyTorch还提供了使用C++和CUDA编程的扩展接口。C++扩展主要有两种形式，一种是使用setuptools提前构建，也可以通过torch.utils.cpp_extension.load()在运行时构建。下面仅介绍第一种方法，第二种方法之后再学习。</p>
<h2 id="基本步骤">基本步骤</h2>
<p>Pytorch,CUDA,C++联合编程的一般步骤如下:</p>
<ol type="1">
<li>首先需要定义一个C++文件，该文件声明了CUDA文件中定义的函数，还需要进行一些检查，并最终将其调用转发给<code>.cu</code>文件。此外，该文件还需要声明将在Python中调用的函数，并使用pybind11绑定到python。OpenPCDet将上述步骤划分为以下几个步骤:
<ol type="1">
<li><p>首先定义一个头文件，该头文件<code>.h</code>中包含了<code>.cu</code>文件中定义的函数和<code>.cpp</code>文件中定义的函数.</p></li>
<li><p>然后定义<code>.cpp</code>文件，其中函数的作用是负责进行一些检查和调用<code>.cu</code>文件中定义的函数</p></li>
<li><p><code>.cu</code>文件是负责执行具体的CUDA编程的操作</p></li>
<li><p>api文件是将<code>.cpp</code>文件中定义的函数和PYBIND11绑定，以便Python调用</p></li>
</ol></li>
<li>在<code>setup.py</code>文件中声明将要编译的模块名称，源文件路径等。</li>
<li>使用import导入声明的模块，使用Python实现其前向和反向传播的计算。</li>
</ol>
<h2 id="举例说明">举例说明</h2>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── ball_query_src</span><br><span class="line">│   ├── api.cpp</span><br><span class="line">│   ├── ball_query.cpp</span><br><span class="line">│   ├── ball_query_cuda.cu</span><br><span class="line">│   ├── ball_query_cuda.h</span><br><span class="line">│   └── cuda_utils.h</span><br><span class="line">├── setup.py</span><br><span class="line">└── test_ball_query.py</span><br></pre></td></tr></table></figure>
<p>项目的目录如上图所示，其中<code>api.cpp</code>文件是将<code>ball_query.cpp</code>声明的函数使用PYBIND11与python进行绑定。其中<code>api.cpp</code>的内容如下:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/serialize/tensor.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/extension.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;ball_query_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">PYBIND11_MODULE</span>(TORCH_EXTENSION_NAME, m) &#123;</span><br><span class="line">    <span class="comment">// 第一个参数表示的是在python中调用的名称，第二个参数是对应的cpp函数，第三个参数对应的是这个函数的说明</span></span><br><span class="line">    m.<span class="built_in">def</span>(<span class="string">&quot;ball_query_wrapper&quot;</span>, &amp;ball_query_wrapper_fast, <span class="string">&quot;ball_query_wrapper_fast&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这里，作者为了使得代码的结构更加清晰，其在<code>ball_query.h</code>文件中分别声明了两个函数，一个是在C++中被调用的函数，另一个是在CUDA中实现的函数。其具体内容如下:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> _BALL_QUERY_GPU_H</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _BALL_QUERY_GPU_H</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/serialize/tensor.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cuda.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cuda_runtime_api.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 与pybind11绑定的函数，其主要作用是调用下面的cuda函数</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ball_query_wrapper_fast</span><span class="params">(<span class="keyword">int</span> b, <span class="keyword">int</span> n, <span class="keyword">int</span> m, <span class="keyword">float</span> radius, <span class="keyword">int</span> nsample, </span></span></span><br><span class="line"><span class="params"><span class="function">	at::Tensor new_xyz_tensor, at::Tensor xyz_tensor, at::Tensor idx_tensor)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA文件中的函数</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ball_query_kernel_launcher_fast</span><span class="params">(<span class="keyword">int</span> b, <span class="keyword">int</span> n, <span class="keyword">int</span> m, <span class="keyword">float</span> radius, <span class="keyword">int</span> nsample, </span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">float</span> *xyz, <span class="keyword">const</span> <span class="keyword">float</span> *new_xyz, <span class="keyword">int</span> *idx)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure>
<p>在<code>.h</code>文件中声明了上述两个文件之后，再分别再<code>ball_query.cpp</code>和<code>ball_query_cuda.cu</code>文件中完成这两个函数的具体实现。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/serialize/tensor.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;THC/THC.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cuda.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cuda_runtime_api.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;ball_query_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> THCState *state;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义检查数据类型的宏</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CHECK_CUDA(x) do &#123; \</span></span><br><span class="line"><span class="meta">	  <span class="meta-keyword">if</span> (!x.type().is_cuda()) &#123; \</span></span><br><span class="line"><span class="meta">		      fprintf(stderr, <span class="meta-string">&quot;%s must be CUDA tensor at %s:%d\n&quot;</span>, #x, __FILE__, __LINE__); \</span></span><br><span class="line"><span class="meta">		      exit(-1); \</span></span><br><span class="line"><span class="meta">		    &#125; \</span></span><br><span class="line"><span class="meta">&#125; while (0)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CHECK_CONTIGUOUS(x) do &#123; \</span></span><br><span class="line"><span class="meta">	  <span class="meta-keyword">if</span> (!x.is_contiguous()) &#123; \</span></span><br><span class="line"><span class="meta">		      fprintf(stderr, <span class="meta-string">&quot;%s must be contiguous tensor at %s:%d\n&quot;</span>, #x, __FILE__, __LINE__); \</span></span><br><span class="line"><span class="meta">		      exit(-1); \</span></span><br><span class="line"><span class="meta">		    &#125; \</span></span><br><span class="line"><span class="meta">&#125; while (0)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CHECK_INPUT(x) CHECK_CUDA(x);CHECK_CONTIGUOUS(x)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 完成输入数据类型的检查，同时调用cu文件中定义的函数</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ball_query_wrapper_fast</span><span class="params">(<span class="keyword">int</span> b, <span class="keyword">int</span> n, <span class="keyword">int</span> m, <span class="keyword">float</span> radius, <span class="keyword">int</span> nsample, </span></span></span><br><span class="line"><span class="params"><span class="function">    at::Tensor new_xyz_tensor, at::Tensor xyz_tensor, at::Tensor idx_tensor)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(new_xyz_tensor);</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(xyz_tensor);</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">float</span> *new_xyz = new_xyz_tensor.data&lt;<span class="keyword">float</span>&gt;();</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">float</span> *xyz = xyz_tensor.data&lt;<span class="keyword">float</span>&gt;();</span><br><span class="line">    <span class="keyword">int</span> *idx = idx_tensor.data&lt;<span class="keyword">int</span>&gt;();</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">ball_query_kernel_launcher_fast</span>(b, n, m, radius, nsample, new_xyz, xyz, idx);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>ball_query_cuda.cu</code>实现</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;ball_query_cuda.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;cuda_utils.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">ball_query_kernel_fast</span><span class="params">(<span class="keyword">int</span> b, <span class="keyword">int</span> n, <span class="keyword">int</span> m, <span class="keyword">float</span> radius, <span class="keyword">int</span> nsample, </span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">const</span> <span class="keyword">float</span> *__restrict__ new_xyz, <span class="keyword">const</span> <span class="keyword">float</span> *__restrict__ xyz, <span class="keyword">int</span> *__restrict__ idx)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// new_xyz: (B, M, 3)</span></span><br><span class="line">    <span class="comment">// xyz: (B, N, 3)</span></span><br><span class="line">    <span class="comment">// output:</span></span><br><span class="line">    <span class="comment">//      idx: (B, M, nsample)</span></span><br><span class="line">    <span class="keyword">int</span> bs_idx = blockIdx.y;</span><br><span class="line">    <span class="keyword">int</span> pt_idx = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (bs_idx &gt;= b || pt_idx &gt;= m) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    new_xyz += bs_idx * m * <span class="number">3</span> + pt_idx * <span class="number">3</span>;</span><br><span class="line">    xyz += bs_idx * n * <span class="number">3</span>;</span><br><span class="line">    idx += bs_idx * m * nsample + pt_idx * nsample;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> radius2 = radius * radius;</span><br><span class="line">    <span class="keyword">float</span> new_x = new_xyz[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">float</span> new_y = new_xyz[<span class="number">1</span>];</span><br><span class="line">    <span class="keyword">float</span> new_z = new_xyz[<span class="number">2</span>];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> cnt = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; n; ++k) &#123;</span><br><span class="line">        <span class="keyword">float</span> x = xyz[k * <span class="number">3</span> + <span class="number">0</span>];</span><br><span class="line">        <span class="keyword">float</span> y = xyz[k * <span class="number">3</span> + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">float</span> z = xyz[k * <span class="number">3</span> + <span class="number">2</span>];</span><br><span class="line">        <span class="keyword">float</span> d2 = (new_x - x) * (new_x - x) + (new_y - y) * (new_y - y) + (new_z - z) * (new_z - z);</span><br><span class="line">        <span class="keyword">if</span> (d2 &lt; radius2)&#123;</span><br><span class="line">            <span class="keyword">if</span> (cnt == <span class="number">0</span>)&#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> l = <span class="number">0</span>; l &lt; nsample; ++l) &#123;</span><br><span class="line">                    idx[l] = k;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            idx[cnt] = k;</span><br><span class="line">            ++cnt;</span><br><span class="line">            <span class="keyword">if</span> (cnt &gt;= nsample) <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ball_query_kernel_launcher_fast</span><span class="params">(<span class="keyword">int</span> b, <span class="keyword">int</span> n, <span class="keyword">int</span> m, <span class="keyword">float</span> radius, <span class="keyword">int</span> nsample, \</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">const</span> <span class="keyword">float</span> *new_xyz, <span class="keyword">const</span> <span class="keyword">float</span> *xyz, <span class="keyword">int</span> *idx)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// new_xyz: (B, M, 3)</span></span><br><span class="line">    <span class="comment">// xyz: (B, N, 3)</span></span><br><span class="line">    <span class="comment">// output:</span></span><br><span class="line">    <span class="comment">//      idx: (B, M, nsample)</span></span><br><span class="line"></span><br><span class="line">    cudaError_t err;</span><br><span class="line"></span><br><span class="line">    <span class="function">dim3 <span class="title">blocks</span><span class="params">(DIVUP(m, THREADS_PER_BLOCK), b)</span></span>;  <span class="comment">// blockIdx.x(col), blockIdx.y(row)</span></span><br><span class="line">    <span class="function">dim3 <span class="title">threads</span><span class="params">(THREADS_PER_BLOCK)</span></span>;</span><br><span class="line"></span><br><span class="line">    ball_query_kernel_fast&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(b, n, m, radius, nsample, new_xyz, xyz, idx);</span><br><span class="line">    <span class="comment">// cudaDeviceSynchronize();  // for using printf in kernel function</span></span><br><span class="line">    err = <span class="built_in">cudaGetLastError</span>();</span><br><span class="line">    <span class="keyword">if</span> (cudaSuccess != err) &#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;CUDA kernel failed : %s\n&quot;</span>, <span class="built_in">cudaGetErrorString</span>(err));</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>至此，ball_query的核心功能已经完成，然后我们需要使用<code>setup.py</code>文件来编译上述文件。<code>setup.py</code>文件的具体实现如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> setuptools <span class="keyword">import</span> find_packages, setup</span><br><span class="line"><span class="keyword">from</span> torch.utils.cpp_extension <span class="keyword">import</span> BuildExtension, CUDAExtension</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_cuda_ext</span>(<span class="params">name, module, sources</span>):</span></span><br><span class="line">    cuda_ext = CUDAExtension(</span><br><span class="line">        name=<span class="string">&#x27;%s.%s&#x27;</span> % (module, name),</span><br><span class="line">        sources=[os.path.join(module.split(<span class="string">&#x27;.&#x27;</span>)[-<span class="number">1</span>], src) <span class="keyword">for</span> src <span class="keyword">in</span> sources]</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>([os.path.join(*module.split(<span class="string">&#x27;.&#x27;</span>), src) <span class="keyword">for</span> src <span class="keyword">in</span> sources])</span><br><span class="line">    <span class="keyword">return</span> cuda_ext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    setup(</span><br><span class="line">        name=<span class="string">&#x27;ballquery&#x27;</span>,</span><br><span class="line">        packages=find_packages(),</span><br><span class="line">        ext_modules=[</span><br><span class="line">            CUDAExtension(<span class="string">&#x27;ball_query_cuda&#x27;</span>,[</span><br><span class="line">                <span class="string">&#x27;ball_query_src/api.cpp&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;ball_query_src/ball_query.cpp&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;ball_query_src/ball_query_cuda.cu&#x27;</span>,  </span><br><span class="line">            ])</span><br><span class="line">        ],</span><br><span class="line">        cmdclass=&#123;</span><br><span class="line">            <span class="string">&#x27;build_ext&#x27;</span>: BuildExtension</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>至此，我们已经生成了上述代码的链接库，但是如果需要将其嵌入到神经网络中，还需要定义其前向传播和反向传播方法。这里我们在<code>test_ball_query.py</code>文件中完成其前向传播和反向传播。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Function, Variable</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> ball_query_cuda</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义该方法的前向传播和反向传播方法</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BallQuery</span>(<span class="params">Function</span>):</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">ctx, radius: <span class="built_in">float</span>, nsample: <span class="built_in">int</span>, xyz: torch.Tensor, new_xyz: torch.Tensor</span>) -&gt; torch.Tensor:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param ctx:</span></span><br><span class="line"><span class="string">        :param radius: float, radius of the balls</span></span><br><span class="line"><span class="string">        :param nsample: int, maximum number of features in the balls</span></span><br><span class="line"><span class="string">        :param xyz: (B, N, 3) xyz coordinates of the features</span></span><br><span class="line"><span class="string">        :param new_xyz: (B, npoint, 3) centers of the ball query</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">            idx: (B, npoint, nsample) tensor with the indicies of the features that form the query balls</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> new_xyz.is_contiguous()</span><br><span class="line">        <span class="keyword">assert</span> xyz.is_contiguous()</span><br><span class="line"></span><br><span class="line">        B, N, _ = xyz.size()</span><br><span class="line">        npoint = new_xyz.size(<span class="number">1</span>)</span><br><span class="line">        idx = torch.cuda.IntTensor(B, npoint, nsample).zero_()</span><br><span class="line">        </span><br><span class="line">        ball_query_cuda.ball_query_wrapper(B, N, npoint, radius, nsample, new_xyz, xyz, idx)</span><br><span class="line">        <span class="keyword">return</span> idx</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">ctx, a=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ball_query = BallQuery.apply</span><br><span class="line"></span><br><span class="line">xyz = torch.randn(<span class="number">2</span>, <span class="number">128</span>, <span class="number">3</span>).cuda()</span><br><span class="line">new_xyz = xyz</span><br><span class="line"></span><br><span class="line">result = ball_query(<span class="number">0.8</span>, <span class="number">3</span>, xyz, new_xyz)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(result.shape)</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://twn29004.top/2022/01/09/pytorchwithcuda/" data-id="cl2d63r91001qmsxcbb83csdn" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-RelationNetworkforObjectDetection" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/01/07/RelationNetworkforObjectDetection/" class="article-date">
  <time datetime="2022-01-06T16:00:00.000Z" itemprop="datePublished">2022-01-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/01/07/RelationNetworkforObjectDetection/">Relation Network for Object Network解读</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201071647839.png" alt="image-20220107164710361" /></p>
<p><a target="_blank" rel="noopener" href="https://github.com/msracver/Relation-Networks-for-Object-Detection">代码链接</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.11575">paper链接</a></p>
<p><a href="https://twn29004.top/">个人博客</a></p>
<h2 id="问题">问题</h2>
<p>本文首先提出了一个目前在目标检测领域的一个共识就是: 丰富的上下文信息和目标之间的关系能够更好的帮助网络去检测目标。但是现有的网络都没有很好的利用这个信息，或者说现有的卷积神经网络都不能很好的处理这些问题。原因是一个场景中往往有很多类别的目标，且类别的数目是不一定的，而且目标的数目也是不一定的。因此，按照之前的CNN网络很难对这些目标之间的关系进行建模。作者受到在NLP领域中非常成功的Transformer的影响，提出了一种自适应的注意力网络用于目标检测领域。作者把这个模块称为目标关系模块。作者将这个关系模块应用于两个任务，一个是<span class="math inline">\(instance-recognition\)</span>和<span class="math inline">\(Duplicate-remova\)</span>阶段。其中前一个阶段就是在提取proposal的特征之后，在对RoI进行调整和rescore之前。后者应用于消除重复的预测阶段，是取代了NMS，因为NMS不是一个端到端的结构。具体应用阶段如下图所示:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201071654018.png" alt="image-20220107165406903" /></p>
<h2 id="解决方法">解决方法</h2>
<h3 id="relation-module的结构">Relation Module的结构</h3>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201071656601.png" alt="image-20220107165648497" /></p>
<p>Relation Module的结构如上图所示。下面分别介绍<span class="math inline">\(W_V,W_Q,W_V, \varepsilon_G\)</span>的计算方法，以及<span class="math inline">\(f_A^n,f_G^m,f_G^n\)</span>的具体含义。</p>
<p>在开始介绍本文所提的Realtion Module之前，作者首先回顾了self-attention的计算方法。<br />
<span class="math display">\[
v^{out}=softmax(\frac{qK^t}{\sqrt{d_k}})V
\]</span><br />
首先介绍<span class="math inline">\(f_A^n\)</span>，其表示对是<span class="math inline">\(n^{th}\)</span>这个RoI的外观特征(Apperance Feature)。<span class="math inline">\(F_G^n\)</span>表示的是<span class="math inline">\(n^{th}\)</span>这个RoI的集合特征，其实就是表示简单的四维边界框。这样，对于一个大小为<span class="math inline">\(N\)</span>的目标集合，其特征可以表示为{(<span class="math inline">\(f^n_A, f^n_G\)</span>)}。第<span class="math inline">\(n^{th}\)</span>个目标关于其他所有目标的关系的计算方法如下:<br />
<span class="math display">\[
f_{R}(n)=\sum_{m}w^{mn}\cdot (W_V \cdot f_A^m)
\]</span><br />
这里的<span class="math inline">\(w^{mn}\)</span>的作用和self-attention中的前半部分基本类似。但是还是存在一些区别。其具体做法如下:<br />
<span class="math display">\[
w^{mn} = \frac{w_G^{mn}\cdot w_{A}^{mn}}{\sum_{k}w_G^{kn}\cdot exp(w_A^{kn})}
\]</span></p>
<p><span class="math display">\[
w_A^{mn} = \frac{dot(W_Kf_A^m, W_Qf_A^n)}{\sqrt{d_K}}
\]</span><br />
上述式子的作用是将<span class="math inline">\(f_A^m\)</span>和<span class="math inline">\(f_A^n\)</span>投影到相同的子空间，然后计算其相关性。其中子空间的维度为<span class="math inline">\(d_K\)</span></p>
<p><span class="math display">\[
w_G^{mn}=max(0， W_G \cdot \varepsilon_G(f_G^m, f_G^n))
\]</span><br />
<span class="math inline">\(\varepsilon_G\)</span>表示的是将<span class="math inline">\((f_G^m，f_G^n)\)</span>嵌入到一个高维空间中，同时为了保证一些旋转不变性和尺度不变性，作者并没有采用原始的描述bbox的参数，而是做了一下变化:<br />
<span class="math display">\[
(log(\frac{|x_m-x_n|}{w_m}), log(\frac{|y_m - y_n|}{h_m}),log(\frac{w_n}{w_m}), log(\frac{h_n}{h_m}))^T
\]</span><br />
这个几何特征嵌入的空间的维度为<span class="math inline">\(d_g\)</span>。其实这里可以将<span class="math inline">\(w_G^{mn}\)</span>理解为公式(3)中的<span class="math inline">\(w_A^{mn}\)</span>的权重。就是在attention的过程中，除了要考虑语义特征之外，对于那些在几何特征上关联性不大的proposal，我们也是不考虑的。换句话说就是在式子(2)中，作者同时考虑了proposal之间的几何和语义关联性。</p>
<p>此外，作者还引入了类似于multi-head的attention设计。其中head的数目用<span class="math inline">\(N_r\)</span>表示。然后将这些head的输出进行拼接之后与原始的语义特征进行拼接。即<br />
<span class="math display">\[
f^n_A=f_A^n+Concat(f_R^1(n),...,f_R^{N_r}(n))
\]</span><br />
上述结构就是作者设计的relation module的主要结构。</p>
<p>正文开头叙述的，作者在目标检测中的两个阶段使用了realtion module.下面将介绍其在不同部分的使用。</p>
<h3 id="rm在instance-recognition中的使用">RM在Instance Recognition中的使用</h3>
<p>原始的Instance Recognition的使用的以下结构:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201071914128.png" alt="image-20220107191420021" /></p>
<p>作者对此提出了一个增强版的检测头，其在两个FC层之间增加了Realtion Module子网络。其结构如下:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201071915082.png" alt="image-20220107191545020" /></p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201071916354.png" alt="image-20220107191602270" /></p>
<h3 id="rm在duplicate-removal中的应用">RM在Duplicate Removal中的应用</h3>
<p>在本节中，作者首先分析了NMS的缺陷。NMS虽然简单，但是由于其采用的是贪心的策略，因此其可能得到的是次优解。此外，目标之间的关系还能对于去除重复有一定的帮助。对此，作者尝试抛弃NMS来做重复预测的去除。也就是NMS-Free的方法。作者将这个重复去除看作一个二分类问题，对于每一个基准框，只有一个被检测的目标能够与之匹配。这样的话可以将这个重复去除问题看做事一个二分类问题。与基准框绑定的预测框为correct，其余的为duplicate的预测。这个预测是能够通过网络来进行的。这个网络的输入就是各个预测的目标。每个目标有一个1-24-D的语义特征，分类分数<span class="math inline">\(s_0\)</span>和预测得三维边界框。网络的得输出事一个二值分类分数<span class="math inline">\(s_1 \in [0,1]\)</span>，1表示的是correct，0表示得duplicate。最终边界框得分数为<span class="math inline">\(s_0 \cdot s_1\)</span>。也就是说，一个好的预测，<span class="math inline">\(s_0, s_1\)</span>都要大才行。这部分的子网络如下图所示:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201071927059.png" alt="image-20220107192723917" /></p>
<p>RM模块是这部分网络得核心模块。对于RM中得几何特征，作者首先将<span class="math inline">\(s_0\)</span>做了一个rank embed，就是使用排名来取代原始得<span class="math inline">\(s_0\)</span>，然后将其嵌入到高维空间，为重得维度为128-D,然后是这个RoI对应得1024-D语义特征也将其转化为128-D得特征，然后将这两个特征进行相加，作为RM模块中得语义特征，bbox作为几何特征得输入。然后将输入经过线性层和softMax之后作为<span class="math inline">\(s_1\)</span>输出，<span class="math inline">\(s_1\)</span>得含义其实就是这个RoI是否被选择与GT绑定。这样就得到了最终得预测输出。</p>
<p>但是这存在一个问题就是，这个输出得标签怎么来呢，由于预测得RoI每次都不同，且数据集中并没有关于RoI的label,这样的话网络是没办法训练的。针对这个问题，作者提出给定一个在基准框和预测的bbox之间的IoU阈值。对于匹配同一个基准狂且大于阈值的预测的bbox，选择分数最大的作为correct的bbox,其余的为duplicate的预测。这样的话就获得了bbox的标签，文中使用的是交叉熵损失来对部分网络进行训练。</p>
<p>文中还发现了不同的预测通常会获得不同的效果，当阈值为0.5时，<span class="math inline">\(mAP_{0.5}\)</span>获得最大，当阈值为0.75时，<span class="math inline">\(mAP_{0.75}\)</span>最大。因此，为了能够在COCO数据集中获得最好的性能，作者设计了多个阈值来获得一个比较均衡的性能。</p>
<h2 id="解决效果">解决效果</h2>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201071941581.png" alt="image-20220107194151453" /></p>
<p>上图中，对于每个精度组合，第一个表示的时2fc head和softNMS组合得到的结果，第二个精度表示的是2fc+RM head+SoftNMS获得的结果，第三个结果表示的是2fc+RM head + e2e得到的结果。</p>
<p>从上述结果中可以看出，作者提出的RM在不同阶段均有很大的提升。</p>
<h2 id="消融实验">消融实验</h2>
<h3 id="在instance-recognition部分的消融实验">在Instance Recognition部分的消融实验</h3>
<p>为了验证所提方法的有效性，作者对进行了丰富的消融实验。对于Instance Recognition部分，作者对是否使用几何特征，以及mutli-head中的head的个数和relation-module的个数进行了探索。其结果如下:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201071946722.png" alt="image-20220107194624603" /></p>
<p>对于几何特征，none的意思是不使用几何特征,unary的意思是将几何特征转化到和语义特征一致的维度，相加，其他操作与none一致。</p>
<p>此外，作者还验证了上述提升并不是因为网络层数加深，参数增多带来的。</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201071948077.png" alt="image-20220107194808989" /></p>
<p>从上述结果中可以看出，使用更多参数的FC (a)VS(b)可以获得0.1mAP的提升。但是增加一层FC之后， (a)VS(c)之后，模型的性能有所下降，分析原因可能是因为层数增多之后模型有所下降。为了能够使得模型能够被更简单的训练，作者在FC层之间加入了残差层(a) VS (d)，加入残差层之后模型性能得到了0.3mAP的提升。此外，作者引入了一个2048-D的全局上下文向量。(a) VS (e)也获得了0.3mAP的提升。(a) VS (f)表示的是作者引入了RM模块对于检测性能的影响。此外，作者还观察到将RoI扩大两倍之后得到的聚合的特征与原始1024-D的语义特征拼接之后，模型的检测性能也得到了一定的提升。即(a) VS (g)。检测精度从29.6提升到了30.4。作者还在此基础上增加了RM模块。即(g) VS (h)。作者还进行了(i)和(j)实验发现增加更多的残差曾和RM层对于模型的性能并没有显著的影响。</p>
<h3 id="在duplicate-removal部分的消融实验">在Duplicate Removal部分的消融实验</h3>
<p>首先也是对于这部分的RM网络的输入特征的一些实验，实验结果如下图所示:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201072004552.png" alt="image-20220107200459387" /></p>
<p>其中，rank <span class="math inline">\(f_R\)</span>中none表示的是不适用<span class="math inline">\(s_0\)</span>,<span class="math inline">\(s_0\)</span>表示的不进行rand embeding。几何bbox中none表示的是不适用几何box，unary表示的是含义与前文相似，将其融入到语义特征中。</p>
<p>此外，作者还将本文所提方法与NMS进行了比较.</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201072017793.png" alt="image-20220107201712700" /></p>
<p>从上表的结果中可以看出,本文所提方法所获得的性能在不同程度上超过了NMS和softNMS。其中e2e表示的同时训练前面提到的两个网络。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://twn29004.top/2022/01/07/RelationNetworkforObjectDetection/" data-id="cl2d63r8t001dmsxccjle3wf3" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/2D-Object-Detection/" rel="tag">2D Object Detection</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-PartA2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/01/02/PartA2/" class="article-date">
  <time datetime="2022-01-01T16:00:00.000Z" itemprop="datePublished">2022-01-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/01/02/PartA2/">PartA2论文解读</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201021917955.png" alt="image-20220102191731775" /></p>
<p><a target="_blank" rel="noopener" href="https://github.com/open-mmlab/OpenPCDet">代码链接</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1907.03670">paper链接</a></p>
<p><a href="https://twn29004.top/">个人博客</a></p>
<h2 id="问题">问题</h2>
<hr />
<p>不同于二维目标检测，三维目标检测中的基准框包含着大量的信息，其能够很自然的提供前景点的标记，甚至提供位于基准框中各个点的内部相对位置。而这些信息对于三维目标检测是非常重要的。三维目标网络的内部相对位置包含了三维基准框内点的分布，这类信息能够很轻易的从点云数据中获得，且包含大量的信息，但是之前从来没有三维边界网络使用这些信息。基于这个观察，本文作者提出了Part-Aware and Part-Aggregation网络.</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201012132549.png" alt="image-20220101213223309" /></p>
<p>内部相对位置的图示。通过这些相对位置，可以帮助网络更好的预测三维边界框。</p>
<h2 id="解决方法">解决方法</h2>
<hr />
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201012135809.png" alt="image-20220101213507656" /></p>
<p>网络的总体结构如上图所示，本文作者设计了一个使用稀疏卷积的U-Net网络。其中这部分Encode-Decode部分的网络如下图所示:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201012136574.png" alt="image-20220101213649420" /></p>
<p>注意，这个与Second中的还是不太一样的，其增加了一个反卷积部分的网络。作者使用这些特征做了两个方面的工作，一个分支是用来预测点的类别，即属于前景点还是属于背景点，另一个分支是用来预测前景点相对边界框的内部相对位置。</p>
<p>关于前景点内部相对位置的计算，其计算公式如下:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201012143824.png" alt="image-20220101214310736" /></p>
<p>其中<span class="math inline">\(x^p\)</span>表示的是点云的原始坐标，<span class="math inline">\(x^c\)</span>表示的边界框的中心点坐标。<span class="math inline">\(w,l,h\)</span>表示的是三维边界框的大小。这样的话三维边界框的中心点的坐标就是(0.5, 0.5, 0.5)。当然，需要计算这些的话就需要计算损失，由于这些相对坐标都是位于[0,1]之间，所以作者使用了一个二值交叉熵损失来作为这个任务的损失。其计算方法如下:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201012150656.png" alt="image-20220101215007583" /></p>
<p>对于点云类别的分类的话，作者使用的是Focal loss损失作为这个任务的损失，其计算方法如下：</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201012150518.png" alt="image-20220101215050275" /></p>
<p>在完成上述任务之后，还需要一些proposal来作为下一个阶段的聚合点的特征的标准。文中作者提出了两种方法，一种是anchor-based的，一个是anchor-free的。anchor-based的方法类似于second中的方法，这个方法可以获得更好的recall，但是其需要消耗更多的计算量以及显存。anchor-free相比之下的recall要差一些，但是其计算量小，效率高，anchor-free可能类似于pointrcnn中的生成方法。</p>
<p>使用上述两种方法生成proposal之后，我们需要根据proposal来聚合周围点的特征。本文中作者提出了一种RoI-aware的特征聚合方法。不同于PointRCNN中简单的聚合proposal对应的逐点的特征，然后使用一个PointNet++来提取这些点的特征来作为proposal的特征。作者观察到这个方法存在一些缺陷，一方面是该方法丧失了很多几何特征，另一方面是在不同的proposal中造成了一些模棱两可的表达。其具体含义如下图所示:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201012200199.png" alt="image-20220101220026051" /></p>
<p>从图中可以看出，蓝色的两个虚线框表示的是不同的proposal，但是他们具有相同的聚合的点，这可能为之后的下游任务带来不利的影响。此外，在对proposal进行特征聚合的时候，作者并没有忽略掉空的voxel。</p>
<p>基于上述问题，作者提出了一种RoI-aware的聚合方法。其将每一个proposal均匀的划分为具有固定空间大小(<span class="math inline">\(L_x,L_y,L_z\)</span>)的体素。用<span class="math inline">\(F\)</span>表示位于3D 体素内的逐点的特征，这里的逐点的特征应该是每个体素的中心点，称为逐点。用<span class="math inline">\(X\)</span>表示逐点的内部相对位置,<span class="math inline">\(b\)</span>表示proposal。对于每一个体素进行池化，对于相对位置的特征，作者使用的是均值池化的方式，即对于一个体素，该体素的特征为位于这个体素内的点的内部相对位置的平均值，语义特征使用的是最大池化的方式。<strong>不同于其他在特征上进行池化的方法，该池化方法在很大程度上保留了proposal中几何特征。而其他基于位置的特征则仅保留一部分语义特征。</strong></p>
<p>此外，作者还使用IoU来对边界框的分数进行重新计算，其计算方法如下:</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201012212996.png" alt="image-20220101221250923" /></p>
<p><strong>感觉和那个任务对齐有点像</strong>。</p>
<hr />
<h2 id="消融实验">消融实验</h2>
<hr />
<ol type="1">
<li><p>使用PointNet++和SparseConvUNet对于网络性能的影响</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201021609772.png" alt="image-20220102160939630" /></p>
<p>从上表中可以看出，使用SparseConvUNet能够更好的提取点云场景的特征，生成更高质量的proposal。</p></li>
<li><p>关于RoI-aware的池化方法对比</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201021829156.png" alt="image-20220102182903804" /></p>
<p>第一行展示的是对于每一个porposal，使用这个类别的平均尺寸作为proposal的大小，然后将proposal同样划分为固定大小的grid。从上表中的结果可以看出，RoI-aware池化方法相比使用均值大小的proposal在性能上远远超过对方。</p></li>
<li><p>此外，作者还探究了RoI-aware中池化大小的影响。</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201021833408.png" alt="image-20220102183320311" /></p>
<p>从上表可以看出，当池化大小大于<span class="math inline">\(12 \times 12 \times 12\)</span>的时候，基本可以获得差不多的性能。</p></li>
<li><p>作者还探究了池化之后不同特征提取方法的区别,即使用全连接层还是使用稀疏卷积层来提取池化后的特征.</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201021835873.png" alt="image-20220102183535797" /></p>
<p>从上表可以看出,使用稀疏卷积和全链接层可以获得相似的性能,但是稀疏卷积所获得精度要高一些.</p></li>
<li><p>作者还对比了不同阶段的网络性能</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201021839353.png" alt="image-20220102183910218" /></p>
<p>从上表中可以看出,第一行和第二行体现了使用Part预测对于网络性能的影响,第一三行和第二四行展示了所提第二阶段的有效性.</p></li>
<li><p>作者还展示了使用不同的指标来作为NMS排名的对于网络性能的影响</p>
<p><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201021841629.png" alt="image-20220102184113520" /></p>
<p>表中展示了使用分类分数和IoU作为指导的分数.从表中可以看出,使用IoU guided的方法可以大幅的提高模型的检测性能.提高了0.7个点.这个和TOOD的指标有点像.</p></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://twn29004.top/2022/01/02/PartA2/" data-id="cl2d63r8k000ymsxc7ccg07l0" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Object-Detection/" rel="tag">Object Detection</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-view_and_reshape" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/01/01/view_and_reshape/" class="article-date">
  <time datetime="2021-12-31T16:00:00.000Z" itemprop="datePublished">2022-01-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/01/01/view_and_reshape/">Pytorch中View和Reshape的区别</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Flag_ing/article/details/109129752">CSDN 参考链接</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://twn29004.top/2022/01/01/view_and_reshape/" data-id="cl2d63r96001xmsxch8f1ct2o" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">下一页 &amp;raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5/">参考链接</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9F%A5%E8%AF%86%E5%88%86%E4%BA%AB/">知识分享</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/2D-Object-Detection/" rel="tag">2D Object Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2D-Object-Detection/" rel="tag">2D Object-Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/3D-Object-Detect-Graph-Network/" rel="tag">3D Object Detect, Graph Network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/3D-Object-Detection/" rel="tag">3D Object Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/3D%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" rel="tag">3D目标检测</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Context-information-self-Attenion/" rel="tag">Context information, self-Attenion</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Fusion/" rel="tag">Fusion</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Instance-Segment/" rel="tag">Instance Segment</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Object-Detection/" rel="tag">Object Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Object-Detection-2D-Object-Detection/" rel="tag">Object Detection, 2D Object Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Segment/" rel="tag">Segment</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8A%80%E5%B7%A7/" rel="tag">技巧</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%82%B9%E4%BA%91%E5%88%86%E5%89%B2/" rel="tag">点云分割</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/2D-Object-Detection/" style="font-size: 15px;">2D Object Detection</a> <a href="/tags/2D-Object-Detection/" style="font-size: 10px;">2D Object-Detection</a> <a href="/tags/3D-Object-Detect-Graph-Network/" style="font-size: 10px;">3D Object Detect, Graph Network</a> <a href="/tags/3D-Object-Detection/" style="font-size: 20px;">3D Object Detection</a> <a href="/tags/3D%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">3D目标检测</a> <a href="/tags/Context-information-self-Attenion/" style="font-size: 10px;">Context information, self-Attenion</a> <a href="/tags/Fusion/" style="font-size: 10px;">Fusion</a> <a href="/tags/Instance-Segment/" style="font-size: 10px;">Instance Segment</a> <a href="/tags/Object-Detection/" style="font-size: 20px;">Object Detection</a> <a href="/tags/Object-Detection-2D-Object-Detection/" style="font-size: 10px;">Object Detection, 2D Object Detection</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/Segment/" style="font-size: 10px;">Segment</a> <a href="/tags/%E6%8A%80%E5%B7%A7/" style="font-size: 10px;">技巧</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">机器学习</a> <a href="/tags/%E7%82%B9%E4%BA%91%E5%88%86%E5%89%B2/" style="font-size: 10px;">点云分割</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">二月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">一月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">十二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">十一月 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/02/27/mmvirtualpioint/">Multimodal Virtual Point 3D Detection论文解读</a>
          </li>
        
          <li>
            <a href="/2022/02/26/2-17%E8%B0%83%E7%A0%94/">(no title)</a>
          </li>
        
          <li>
            <a href="/2022/01/14/Faster-RCNN/">Faster-RCNN论文解读</a>
          </li>
        
          <li>
            <a href="/2022/01/13/3D_IoU_Net/">3D IoU-Net论文解读</a>
          </li>
        
          <li>
            <a href="/2022/01/12/YOLOF/">YOLOF论文解读</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 twn29004<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>
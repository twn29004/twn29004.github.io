<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Point cloud transformer论文解读 | twn29004&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="代码链接 paper链接 论文总结 本文提出了一种在适用于点云的Transformer结构。根据点云数据的特点进一步改善了Transformer的结构。其主要做了三点改进:  基于坐标的输入嵌入方法 改进的offset-attention方法(想法主要来源于图神经网络) 邻近点嵌入方法  下面依次介绍上述三种改进点以及改进的原因。 首先介绍原始的Transformer结构在">
<meta property="og:type" content="article">
<meta property="og:title" content="Point cloud transformer论文解读">
<meta property="og:url" content="http://twn29004.top/2021/12/08/PCT(Meng%E2%80%94Hao)/index.html">
<meta property="og:site_name" content="twn29004&#39;s Blog">
<meta property="og:description" content="代码链接 paper链接 论文总结 本文提出了一种在适用于点云的Transformer结构。根据点云数据的特点进一步改善了Transformer的结构。其主要做了三点改进:  基于坐标的输入嵌入方法 改进的offset-attention方法(想法主要来源于图神经网络) 邻近点嵌入方法  下面依次介绍上述三种改进点以及改进的原因。 首先介绍原始的Transformer结构在">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112081119407.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112081123918.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112081239610.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112081244793.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112081245640.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112081259234.png">
<meta property="article:published_time" content="2021-12-07T16:00:00.000Z">
<meta property="article:modified_time" content="2021-12-08T06:40:00.000Z">
<meta property="article:author" content="twn29004">
<meta property="article:tag" content="Segment">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112081119407.png">
  
    <link rel="alternate" href="/atom.xml" title="twn29004&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">twn29004&#39;s Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://twn29004.top"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-PCT(Meng—Hao)" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2021/12/08/PCT(Meng%E2%80%94Hao)/" class="article-date">
  <time datetime="2021-12-07T16:00:00.000Z" itemprop="datePublished">2021-12-08</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Point cloud transformer论文解读
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112081119407.png" alt="1" /></p>
<p><a target="_blank" rel="noopener" href="https://github.com/MenghaoGuo/PCT">代码链接</a></p>
<p><a target="_blank" rel="noopener" href="https://doi.org/10.1007/s41095-021-0229-5">paper链接</a></p>
<h2 id="论文总结">论文总结</h2>
<p>本文提出了一种在适用于点云的Transformer结构。根据点云数据的特点进一步改善了Transformer的结构。其主要做了三点改进:</p>
<ol type="1">
<li>基于坐标的输入嵌入方法</li>
<li>改进的offset-attention方法(想法主要来源于图神经网络)</li>
<li>邻近点嵌入方法</li>
</ol>
<p>下面依次介绍上述三种改进点以及改进的原因。</p>
<p>首先介绍原始的Transformer结构在点云中的使用。</p>
<p><img src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112081123918.png" alt="2" /></p>
<p>使用点云的Encoder结构来提取点云的特征。首先使用一个输入嵌入层来转化点云的坐标，就是将三维的点云坐标映射到一个更高维的空间。这一步的目的是使得具有相似语义信息的点云能够在高维空间中更加靠近。文中这一步是使用线性层来完成的。然后将经过转化后的坐标输入到级联的Attention网络中。然后将各个层级的Attention网络的输出拼接起来，再经过一个线性层以得到一个逐点的特征，然后使用一个Max Pooling或者Mean Pooling操作来获得一个全局的特征。这样我们就可以使用全局的特征来进行点云的分类了。如果是其他任务的话，可以把全局特征和前面逐点的特征进行拼接，在来进行下一步的任务(这个和PointNet++中的操作是一致的)。</p>
<p>上述过程描述的就是使用基于坐标的输入嵌入方法和原始的Transformer结构结合起来处理点云的网络。</p>
<p>在介绍offset-Attention方法之前，需要先介绍一下原始的self-Attenion的机制:<br />
<span class="math display">\[
\hat{A}=(\hat{a})_{i,j}=Q \cdot K^T \\
F_{sa} = A \cdot V \\
F_{out} = SA(F_{in}) = LBR(F_{sa}) + F_{in}
\]</span><br />
上述公式中<span class="math inline">\(A\)</span>是<span class="math inline">\(\hat{A}\)</span>的归一化后的结果，具体的归一化的方法可以参考原论文。offset-Attention的方法就是将<span class="math inline">\(LBR\)</span>中的<span class="math inline">\(F_{sa}\)</span>变化为<span class="math inline">\(F_{sa}\)</span>和<span class="math inline">\(F_{in}\)</span>的差。这样的话就可以有:<br />
<span class="math display">\[
F_{out}=OA(F_{in})=LRB(F_{in} - F_{sa}) + F_{in}
\]</span><br />
<img src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112081239610.png" alt="image-20211208123926572" /></p>
<p>作者把这样改进之后的PCT记为SPCT.</p>
<p>此外，作者还注意到，PCT在提取点云特征的时候，只关注到了点云的全局特征，而忽略了局部特征，因此，受到PointNet++的影响，作者引入了一个局部特征聚合的机制。和PointNet++一样，进行了一个Sampling和Grouping。然后使用PointNet来提取局部点云的特征，然后将这些采样的点及其对应的聚合的特征作为Attention网络的输入.此举大大提高了模型的性能。具体可见下表:</p>
<p><img src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112081244793.png" alt="image-20211208124405743" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112081245640.png" alt="image-20211208124541575" /></p>
<p>从上述表格中可以看出，SPCT和那个局部特征聚合都对模型的性能有所提升。此外，作者还做了计算资源方面的分析。资源消耗对比如下表所示:</p>
<p><img src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112081259234.png" alt="image-20211208125922176" /></p>
<p>从上表可以看出，NPCT和SPCT的资源消耗相差不是很大，但是精度有一定的提升。PCT相比其余两个的参数量和计算量要多很多，但是所需的浮点运算的次数仍比PointNet++(MSG)要少很多。精度却有很大的提升。</p>
<h2 id="可用知识点">可用知识点</h2>
<ol type="1">
<li>在点云中使用Transformer时，因为点云自带位置信息，因此可以考虑将位置嵌入和输入嵌入结合起来。</li>
<li>在点云中使用Transformer时，可以考虑使用offset-Attenion方法来替换self-Attention方法。</li>
<li>在点云中使用Transformer时，可以考虑从使用类似于PointNet2中的局部特征聚合的方法来聚合局部信息。</li>
</ol>
<h2 id="常用句式">常用句式</h2>
<ol type="1">
<li>Therefore, the whole self-attention process is permutation-invariant, making it well-suited to the disordered, irregular domain presented by point clouds. 解释了self-attention适合于point cloud处理的原因。</li>
</ol>
<h2 id="代码解读">代码解读</h2>
<p>[挖坑]</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://twn29004.top/2021/12/08/PCT(Meng%E2%80%94Hao)/" data-id="cl2d63r8i000vmsxcberb713b" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Segment/" rel="tag">Segment</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/12/11/%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8F%AF%E8%A1%8C%E6%80%A7/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          霍夫丁不等式证明学习的可行性
        
      </div>
    </a>
  
  
    <a href="/2021/12/07/Pointformer/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">3D ObJect Detection with Pointformer</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5/">参考链接</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9F%A5%E8%AF%86%E5%88%86%E4%BA%AB/">知识分享</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/2D-Object-Detection/" rel="tag">2D Object Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2D-Object-Detection/" rel="tag">2D Object-Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/3D-Object-Detect-Graph-Network/" rel="tag">3D Object Detect, Graph Network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/3D-Object-Detection/" rel="tag">3D Object Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/3D%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" rel="tag">3D目标检测</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Context-information-self-Attenion/" rel="tag">Context information, self-Attenion</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Fusion/" rel="tag">Fusion</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Instance-Segment/" rel="tag">Instance Segment</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Object-Detection/" rel="tag">Object Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Object-Detection-2D-Object-Detection/" rel="tag">Object Detection, 2D Object Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Segment/" rel="tag">Segment</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8A%80%E5%B7%A7/" rel="tag">技巧</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%82%B9%E4%BA%91%E5%88%86%E5%89%B2/" rel="tag">点云分割</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/2D-Object-Detection/" style="font-size: 15px;">2D Object Detection</a> <a href="/tags/2D-Object-Detection/" style="font-size: 10px;">2D Object-Detection</a> <a href="/tags/3D-Object-Detect-Graph-Network/" style="font-size: 10px;">3D Object Detect, Graph Network</a> <a href="/tags/3D-Object-Detection/" style="font-size: 20px;">3D Object Detection</a> <a href="/tags/3D%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">3D目标检测</a> <a href="/tags/Context-information-self-Attenion/" style="font-size: 10px;">Context information, self-Attenion</a> <a href="/tags/Fusion/" style="font-size: 10px;">Fusion</a> <a href="/tags/Instance-Segment/" style="font-size: 10px;">Instance Segment</a> <a href="/tags/Object-Detection/" style="font-size: 20px;">Object Detection</a> <a href="/tags/Object-Detection-2D-Object-Detection/" style="font-size: 10px;">Object Detection, 2D Object Detection</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/Segment/" style="font-size: 10px;">Segment</a> <a href="/tags/%E6%8A%80%E5%B7%A7/" style="font-size: 10px;">技巧</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">机器学习</a> <a href="/tags/%E7%82%B9%E4%BA%91%E5%88%86%E5%89%B2/" style="font-size: 10px;">点云分割</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">二月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">一月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">十二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">十一月 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/02/27/mmvirtualpioint/">Multimodal Virtual Point 3D Detection论文解读</a>
          </li>
        
          <li>
            <a href="/2022/02/26/2-17%E8%B0%83%E7%A0%94/">(no title)</a>
          </li>
        
          <li>
            <a href="/2022/01/14/Faster-RCNN/">Faster-RCNN论文解读</a>
          </li>
        
          <li>
            <a href="/2022/01/13/3D_IoU_Net/">3D IoU-Net论文解读</a>
          </li>
        
          <li>
            <a href="/2022/01/12/YOLOF/">YOLOF论文解读</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 twn29004<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>
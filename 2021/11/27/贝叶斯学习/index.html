<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>贝叶斯学习 | twn29004&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="贝叶斯理论 计算后验概率 \[ P(h|D)&#x3D;\frac{P(D|h)p(h)}{p(D)} \] 其中，\(P(D|h)\)是根据数据观察到的条件概率，\(p(h)\)是先验概率。我们要做的就是在假设空间中找到具有最大后验概率的假设。那么就有: \[ h_{MAP}&#x3D; arg max_{h \in H}P(h|D)&#x3D;argmax_{h \in H} \frac{P(D|h)p(h)">
<meta property="og:type" content="article">
<meta property="og:title" content="贝叶斯学习">
<meta property="og:url" content="http://twn29004.top/2021/11/27/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="twn29004&#39;s Blog">
<meta property="og:description" content="贝叶斯理论 计算后验概率 \[ P(h|D)&#x3D;\frac{P(D|h)p(h)}{p(D)} \] 其中，\(P(D|h)\)是根据数据观察到的条件概率，\(p(h)\)是先验概率。我们要做的就是在假设空间中找到具有最大后验概率的假设。那么就有: \[ h_{MAP}&#x3D; arg max_{h \in H}P(h|D)&#x3D;argmax_{h \in H} \frac{P(D|h)p(h)">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/twn29004/myimg/raw/master/imgs/202111211006281.png">
<meta property="og:image" content="https://gitee.com/twn29004/myimg/raw/master/imgs/202111211323660.png">
<meta property="og:image" content="https://gitee.com/twn29004/myimg/raw/master/imgs/202111211337106.png">
<meta property="og:image" content="https://gitee.com/twn29004/myimg/raw/master/imgs/202111212130947.png">
<meta property="og:image" content="https://gitee.com/twn29004/myimg/raw/master/imgs/202111212141086.png">
<meta property="og:image" content="https://gitee.com/twn29004/myimg/raw/master/imgs/202111211352341.png">
<meta property="og:image" content="https://gitee.com/twn29004/myimg/raw/master/imgs/202111211708912.png">
<meta property="og:image" content="https://gitee.com/twn29004/myimg/raw/master/imgs/202111211900632.png">
<meta property="og:image" content="https://gitee.com/twn29004/myimg/raw/master/imgs/202111212023894.png">
<meta property="article:published_time" content="2021-11-26T16:00:00.000Z">
<meta property="article:modified_time" content="2021-11-28T02:44:13.337Z">
<meta property="article:author" content="twn29004">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/twn29004/myimg/raw/master/imgs/202111211006281.png">
  
    <link rel="alternate" href="/atom.xml" title="twn29004&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">twn29004&#39;s Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://twn29004.top"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-贝叶斯学习" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2021/11/27/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E4%B9%A0/" class="article-date">
  <time datetime="2021-11-26T16:00:00.000Z" itemprop="datePublished">2021-11-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%9F%A5%E8%AF%86%E5%88%86%E4%BA%AB/">知识分享</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      贝叶斯学习
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="贝叶斯理论">贝叶斯理论</h2>
<h3 id="计算后验概率">计算后验概率</h3>
<p><span class="math display">\[
P(h|D)=\frac{P(D|h)p(h)}{p(D)}
\]</span></p>
<p>其中，<span class="math inline">\(P(D|h)\)</span>是根据数据观察到的条件概率，<span class="math inline">\(p(h)\)</span>是先验概率。我们要做的就是在假设空间中找到具有最大后验概率的假设。那么就有:</p>
<p><span class="math display">\[
h_{MAP}= arg max_{h \in H}P(h|D)=argmax_{h \in H} \frac{P(D|h)p(h)}{p(D)}\\=arg max_{h \in H}P(D|h)p(h)
\]</span></p>
<p>如果每个假设出现的概率相等，等上述问题退化为<span class="math inline">\(h_{ML}=argmax_{h \in H}P(D|h)\)</span>,这个就是极大似然假设。上面那个是极大后验假设。</p>
<p>使用极大似然假设进行癌症诊断的例子：</p>
<ol type="1">
<li><p>两个假设：1) 病人有癌症，2) 病人没有癌症</p></li>
<li><p>两种可能的测试输出: 1) positive,记为+ 2) negative,记为-</p></li>
<li><p>先验知识：P(cancer) = 0.008 P(not cancer)=0.992 P(+|cancer)=0.98 P(- |cancer)=0.02</p>
<p>P(- |not cancer) = 0.97 P(+|not cancer) = 0.03</p></li>
<li><p>分别计算病人检测结果为阳性，其患癌症和不患癌症哪个概率大<br />
<span class="math display">\[
P(cancer|+)=\frac{P(+|cancer)*P(cancer)}{P(+)} \\
P(not cancer | +) = \frac{P(+ | not cancer)*P(not cancer)}{P(+)}
\]</span><br />
从上述式子可以看出，只用比较两个式子的分子部分就可以对比谁的概率大。</p></li>
</ol>
<h2 id="极大似然假设和极大后验概率假设的区别">极大似然假设和极大后验概率假设的区别</h2>
<ol type="1">
<li><p>极大后验概率假设：<br />
<span class="math display">\[
h_{MAP}= arg max_{h \in H}P(h|D)=argmax_{h \in H} \frac{P(D|h)p(h)}{p(D)}\\=arg max_{h \in H}P(D|h)p(h)
\]</span></p></li>
<li><p>极大似然假设</p>
<p>当假设空间中每个假设出现的概率都相同时，我们就可以不再考虑极大后验概率中的<span class="math inline">\(P(h)\)</span>，仅考虑数据<span class="math inline">\(D\)</span>对于假设<span class="math inline">\(h\)</span>的似然值<span class="math inline">\(P(D|h)\)</span>。则上述问题退化为:<br />
<span class="math display">\[
h_{ML}=argmax_{h\in H}P(D|h)
\]</span></p></li>
</ol>
<h2 id="一般概率准则">一般概率准则</h2>
<ol type="1">
<li><p>求和准则： 如果两个事件不是互相独立的，则A或B发生的概率可以使用一下方法进行计算:</p>
<p><span class="math inline">\(P(A \or B) = P(A) + P(B) - P(A \and B)\)</span></p></li>
<li><p>相乘准则：</p>
<ol type="1">
<li><p>如果两个事件不是独立的，则：<span class="math inline">\(P(A \and B)=P(A | B)*P(B) =P(B|A)*P(A)\)</span></p></li>
<li><p>如果两个事件是独立的，则: <span class="math inline">\(P(A \and B)=P(A)*P(B)\)</span></p></li>
<li><p>当且仅当:<br />
<span class="math display">\[
P(A|B)=P(A) or \\
P(B|A) = P(B) or \\
P(AB)=P(A)P(B)
\]</span><br />
我们可以说事件A和事件B是独立的</p></li>
<li><p>全概率准则:</p>
<p>如果<span class="math inline">\(A_1...A_n\)</span>是互斥的，独立的事件，即<span class="math inline">\(P(B) = \sum_{1}^{n}P(B|A_i)P(A_i)\)</span></p>
<p><img src="https://gitee.com/twn29004/myimg/raw/master/imgs/202111211006281.png" alt="image-20211121100603229" /></p>
<p>上表中，第三列是各个年龄段患病的概率，最后一列是各个年龄段所占的比例。则求整个疾病的患病概率<span class="math inline">\(P(D)\)</span>。</p></li>
</ol></li>
</ol>
<h2 id="最小描述长度">最小描述长度</h2>
<p>最小描述长度(Minimum Description Length Principle MDL)</p>
<ol type="1">
<li><p>基本思想：</p>
<ol type="1">
<li>对于一个给定的假设集合和数据集，我们需要在假设集中找到或者合并一些使得数据被压缩的最小的假设。</li>
</ol></li>
<li><p>最小描述长度原理:</p>
<p><span class="math inline">\(h_{MDL}=arg \min_{h \in H} L_{C_1}(h)+L_{C_{2}}(D|h)\)</span>,其中<span class="math inline">\(L_{c_1}(h)\)</span>表示的是模型的复杂度，其具体表示描述整个模型所需的最小比特, <span class="math inline">\(L_{C_2}(D|h)\)</span>表示的是描述使用假设编码后的最小长度。在这里可以代表模型的错误率。所以最小描述长度就是在模型复杂度和模型性能之间做一个权衡。</p></li>
</ol>
<h2 id="贝叶斯最优分类器">贝叶斯最优分类器</h2>
<ol type="1">
<li><p>核心思想：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/lsjseu/article/details/12285407">贝叶斯最优分类器</a></p>
<p><strong>一般来说，新实例的最可能的分类可以通过合并所有假设的预测得到。用后验概率来加权</strong>。如果新样例可能分类可取集合<span class="math inline">\(V\)</span>的任一值<span class="math inline">\(v_j\)</span>，那么概率<span class="math inline">\(P(v_j|D)\)</span>表示新实例<span class="math inline">\(v_j\)</span>被正确分类的概率，其值为:<br />
<span class="math display">\[
P(v_i|D)=\sum_{h_j \in H}P(v_i|h_j)P(h_j|D)
\]</span><br />
新实例的最优分类为使<span class="math inline">\(P(v_i|D)\)</span>最大的<span class="math inline">\(v_i\)</span>的值。因此贝叶斯最优分类器有：<br />
<span class="math display">\[
arg\max_{v_i \in V}\sum_{h_j \in H}P(v_i|h_j)P(h_j|D)
\]</span></p></li>
<li><p>贝叶斯最优分类器:</p>
<ol type="1">
<li>该方法最大化了新实例被分类正确的可能性</li>
<li>在使用相同的假设空间和先验知识的条件下，没有其他的模型能够超过该方法</li>
<li>该方法所作的决策不能对应到假设空间中某个具体的假设上</li>
</ol></li>
<li><p>贝叶斯最优分类器存在的问题：需要计算所有可能的模型和假设，当假设空间很大时，这个计算是耗时的。因此可以使用Gibbs算法来解决</p></li>
</ol>
<h2 id="吉布斯算法">吉布斯算法</h2>
<p>为了解决贝叶斯最优分类器难以计算的问题，提出了吉布斯算法。吉布斯算法的基本思想就是:</p>
<p>根据后验概率在假设空间的分布，随机的从假设空间选取一个假设来对新实例进行分类，在具体的条件下，该方法的分类错误率小于两倍的贝叶斯最优分类器的错误率。</p>
<p><img src="https://gitee.com/twn29004/myimg/raw/master/imgs/202111211323660.png" alt="image-20211121132357605" /></p>
<p>但是，通常从假设空间采样是困难的，因为：</p>
<ol type="1">
<li><span class="math inline">\(P(h|D)\)</span>难以计算</li>
<li>对于没有参数的分类器例如SVM，<span class="math inline">\(P(h|D)\)</span>不可能计算</li>
<li><span class="math inline">\(P(h|D)\)</span>在假设空间很大时非常的小。</li>
</ol>
<p>为了解决上述问题，提出了Bagging 分类器算法。通过将从假设空间采样转化为从训练数据中进行采样。</p>
<h2 id="bagging-分类器算法">Bagging 分类器算法</h2>
<ol type="1">
<li><p>Boostrap采样</p>
<p>对于给定的训练数据D,其中包含m个训练样本，从D中有放回的随机采样n个样本构成<span class="math inline">\(D^i\)</span>数据集。<span class="math inline">\(D^i\)</span>理论上有0.37的数据没有被采样到。</p></li>
<li><p>Bagging算法</p>
<p>构建<span class="math inline">\(k\)</span>个<span class="math inline">\(D^i\)</span>，对灭一个<span class="math inline">\(D^i\)</span>分别构建一个分类器<span class="math inline">\(h^i\)</span>,在对新实例分类时，所有的分类器以相同的权重进行投票:</p>
<p><img src="https://gitee.com/twn29004/myimg/raw/master/imgs/202111211337106.png" alt="image-20211121133725061" /></p></li>
</ol>
<h2 id="偏差方差分解"><strong>偏差方差分解</strong></h2>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/38853908">参考链接</a></p>
<p><img src="https://gitee.com/twn29004/myimg/raw/master/imgs/202111212130947.png" alt="image-20211121213036863" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/twn29004/myimg/raw/master/imgs/202111212141086.png" alt="image-20211121214117003" /></p>
<p>注意借助预测值的期望这个值来使得方差和偏差能够联系起来。此外，还要知道偏差和方差的计算方法，这样才能刚好的往这个方向去凑:<br />
<span class="math display">\[
var=E_{D}[g^{(D)}(x) - E_{D}[g^{(D)}(x)]] \\
bias = E_{D}[y - E_{D}[g^{(D)}(x)]]  \\
\sigma^2 = (y - y_D)^2
\]</span><br />
注意上述公式中的第二个关于偏差的计算中，式子中的<span class="math inline">\(y\)</span>不是表示数据标签，而是训练数据的真实标签，因为训练所用的标签和真实的标签可能存在一定的误差。其中<span class="math inline">\(y_D\)</span>表示的是数据在训练时的标签。</p>
<p>偏差方差分解的核心原理就是利用已知的方差偏差的计算公式不断的去凑。第一次用训练结果的期望去凑，第二次用训练时的标签<span class="math inline">\(y_D\)</span>去凑。</p>
<p>方差描述的是不同训练集训练出的模型的差距。</p>
<p>偏差描述的是所有可能的训练数据集训练的所有模型的输出的平均值与真实模型之间输出值之间的差距。</p>
<h2 id="朴素贝叶斯分类器--可能会出计算题">朴素贝叶斯分类器--可能会出计算题</h2>
<p>假设训练集中的一个实例可以划分为有n个属性的组合。<span class="math inline">\(&lt;a_1,a_2,...a_n&gt;\)</span>，同时，类别空间<span class="math inline">\(V\)</span>是一个有限的集合。</p>
<p>使用贝叶斯方法对新实例进行分类:<br />
<span class="math display">\[
v_{MAP}=arg \max_{v_J \in V}P(v_j|a_1,a_2,...a_n) \\
v_{MAP}=arg \max_{v_J \in V]}\frac{P(a_1,a_2,..a_n|v_j)P(v_j)}{P(a_1,a_2,..a_n)}
\]</span><br />
如何计算<span class="math inline">\(P(v_j)\)</span>和<span class="math inline">\(P(a_1,a_2,...a_n|v_j)\)</span>：</p>
<ol type="1">
<li><span class="math inline">\(P(v_j)\)</span>是这一类别在训练数据中出现的概率</li>
<li><strong><span class="math inline">\(P(a_1, a_2, ...,a_n|v_j)\)</span>不太可信，除非我们有一个非常非常大的训练样本。</strong></li>
</ol>
<p>为了解决<span class="math inline">\(P(a_1,a_2, ..a_n|v_j)\)</span>难以直接计算的问题，提出了贝叶斯假设。其核心内容就是所有的属性值都是相互独立的。所以有:<br />
<span class="math display">\[
P(a_1,a_2,...a_n|v_j)=\prod_{i}P(a_i|v_i)
\]</span><br />
<img src="https://gitee.com/twn29004/myimg/raw/master/imgs/202111211352341.png" alt="image-20211121135228260" /></p>
<p>计算的例子。</p>
<h2 id="贝叶斯信念网络----计算题">贝叶斯信念网络----计算题</h2>
<p>贝叶斯最优分类器难以计算，朴素贝叶斯要求各个属性相互独立，条件太过严格。贝叶斯信念网络提出了一种折衷的方法。</p>
<h3 id="条件独立">条件独立</h3>
<p><img src="https://gitee.com/twn29004/myimg/raw/master/imgs/202111211708912.png" alt="image-20211121170821847" /></p>
<p>在给定<span class="math inline">\(z\)</span>的请款下，对于任意的<span class="math inline">\(x\)</span>，都有<span class="math inline">\(P(X=x_i|Y=y_j,Z=z_k)=P(x=x_i|Z=z_k)\)</span>或者说<span class="math inline">\(P(X|Y,Z)=P(X|Z)\)</span>。我们就称<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>关于<span class="math inline">\(Z\)</span>是条件独立的。</p>
<p>这样的话，使用条件独立可以将朴素贝叶斯调整为:<br />
<span class="math display">\[
P(X,Y|Z)=P(X|Y,Z)*P(Y|Z)=P(X|Z)*P(Y|Z) 
\]</span><br />
上述式子在另一个角度证明了朴素贝叶斯。因为朴素贝叶斯中<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>是相互独立的。</p>
<p><img src="https://gitee.com/twn29004/myimg/raw/master/imgs/202111211900632.png" alt="image-20211121190026571" /></p>
<p>计算下列事件发生的概率:</p>
<ol type="1">
<li><span class="math inline">\(P(W|S)\)</span></li>
<li><span class="math inline">\(P(S|W)\)</span></li>
<li><span class="math inline">\(P(S|R,W)\)</span></li>
</ol>
<p><span class="math display">\[
\begin{equation}
\begin{aligned}
P(W|S) &amp;= \frac{P(W,S)}{P(S)} \\
&amp;= \frac{P(W,S|R)*P(R) +P(W,S|\neg R)*P(\neg R)}{P(S)} \\
&amp;= \frac{P(W,S,R) + P(W,S,\neg R)}{P(S)} \\
&amp;= \frac{P(W,S,R)}{P(R,S)}*\frac{P(R,S)}{R(S)} + \frac{P(W,\neg R,S)}{P(\neg R, S)}*\frac{P(\neg R,S)}{P(S)} \\  
&amp;= P(W|R,S)*P(R|S) + P(W | \neg R,S)*P(\neg R | S) \\
&amp;= P(W|R,S)*P(R) + P(W|\neg R, S)*P(\neg R) \\
\end{aligned}
\end{equation}
\]</span></p>
<p>第三行变换的依据是根据已知条件凑出来的。最后一行的变化是因为<span class="math inline">\(R\)</span>和<span class="math inline">\(S\)</span>是独立的。<br />
<span class="math display">\[
P(S|W) = \frac{P(W|S)*P(S)}{P(W)} \\
\begin{equation}
\begin{aligned}
P(W) &amp;= P(W|R,S)*P(R , S) + P(W|R, \neg S) *P(R, \neg S) \\
&amp;+ P(W|\neg R, S) * P(\neg R. S) + P(W|\neg R, \neg S) *P(\neg R, \neg S) 
\end{aligned}
\end{equation} \\
\\
P(R,S) = P(R)*P(S)
\]</span></p>
<p><span class="math display">\[
\begin{equation}
\begin{aligned}
P(S|R,W) &amp;= \frac{P(R,S,W)}{P(R,W)} \\
&amp;= \frac{P(W|R,S)*P(R,S)}{P(R,W)} \\
&amp;= \frac{P(W|R,S)*P(R)*P(S)}{P(R,W)} \\
&amp;= \frac{P(W|R,S)*P(S)}{P(W|R)}
\end{aligned}
\end{equation} \\
\]</span></p>
<p><span class="math display">\[
\begin{equation}
\begin{aligned}
P(W|R) &amp;= \frac{P(W,R)}{P(R)} \\
&amp;= \frac{P(W.R|S) * P(S) + P(W,R|\neg S)*P(\neg S)}{P(R)} \\
&amp;= \frac{P(W,R,S) + P(W,R,\neg S)}{P(R)} \\
&amp;= \frac{P(W, R,S)}{P(R,S)}*\frac{P(R,S)}{P(R)} + \frac{P(W, R,\neg S)}{P(R,\neg S)}*\frac{P(R,\neg S)}{P(R)} \\
&amp;= P(W|R,S)*P(S|R) + P(W|R, \neg S)*P(\neg S|R) \\
&amp;= P(W|R,S)*P(S) + P(W|R, \neg S)*P(\neg S)
\end{aligned}
\end{equation}
\]</span></p>
<p><img src="https://gitee.com/twn29004/myimg/raw/master/imgs/202111212023894.png" alt="image-20211121202358797" /></p>
<p>​</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://twn29004.top/2021/11/27/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E4%B9%A0/" data-id="cl2d63r9a0023msxcae6q2vsw" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/11/27/RPVNet/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          RPVNet解读
        
      </div>
    </a>
  
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5/">参考链接</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9F%A5%E8%AF%86%E5%88%86%E4%BA%AB/">知识分享</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/2D-Object-Detection/" rel="tag">2D Object Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2D-Object-Detection/" rel="tag">2D Object-Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/3D-Object-Detect-Graph-Network/" rel="tag">3D Object Detect, Graph Network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/3D-Object-Detection/" rel="tag">3D Object Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/3D%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" rel="tag">3D目标检测</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Context-information-self-Attenion/" rel="tag">Context information, self-Attenion</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Fusion/" rel="tag">Fusion</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Instance-Segment/" rel="tag">Instance Segment</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Object-Detection/" rel="tag">Object Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Object-Detection-2D-Object-Detection/" rel="tag">Object Detection, 2D Object Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Segment/" rel="tag">Segment</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8A%80%E5%B7%A7/" rel="tag">技巧</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%82%B9%E4%BA%91%E5%88%86%E5%89%B2/" rel="tag">点云分割</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/2D-Object-Detection/" style="font-size: 15px;">2D Object Detection</a> <a href="/tags/2D-Object-Detection/" style="font-size: 10px;">2D Object-Detection</a> <a href="/tags/3D-Object-Detect-Graph-Network/" style="font-size: 10px;">3D Object Detect, Graph Network</a> <a href="/tags/3D-Object-Detection/" style="font-size: 20px;">3D Object Detection</a> <a href="/tags/3D%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">3D目标检测</a> <a href="/tags/Context-information-self-Attenion/" style="font-size: 10px;">Context information, self-Attenion</a> <a href="/tags/Fusion/" style="font-size: 10px;">Fusion</a> <a href="/tags/Instance-Segment/" style="font-size: 10px;">Instance Segment</a> <a href="/tags/Object-Detection/" style="font-size: 20px;">Object Detection</a> <a href="/tags/Object-Detection-2D-Object-Detection/" style="font-size: 10px;">Object Detection, 2D Object Detection</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/Segment/" style="font-size: 10px;">Segment</a> <a href="/tags/%E6%8A%80%E5%B7%A7/" style="font-size: 10px;">技巧</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">机器学习</a> <a href="/tags/%E7%82%B9%E4%BA%91%E5%88%86%E5%89%B2/" style="font-size: 10px;">点云分割</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">二月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">一月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">十二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">十一月 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/02/27/mmvirtualpioint/">Multimodal Virtual Point 3D Detection论文解读</a>
          </li>
        
          <li>
            <a href="/2022/02/26/2-17%E8%B0%83%E7%A0%94/">(no title)</a>
          </li>
        
          <li>
            <a href="/2022/01/14/Faster-RCNN/">Faster-RCNN论文解读</a>
          </li>
        
          <li>
            <a href="/2022/01/13/3D_IoU_Net/">3D IoU-Net论文解读</a>
          </li>
        
          <li>
            <a href="/2022/01/12/YOLOF/">YOLOF论文解读</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 twn29004<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>
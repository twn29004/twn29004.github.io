<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>twn29004's Blog</title><meta name="author" content="twn29004"><meta name="copyright" content="twn29004"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="twn29004&#39;s Blog">
<meta property="og:url" content="http://twn29004.top/page/3/index.html">
<meta property="og:site_name" content="twn29004&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112082242974.jpeg">
<meta property="article:author" content="twn29004">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112082242974.jpeg"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://twn29004.top/page/3/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?da945d048bc901ec4ee07f4643119577";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: twn29004","link":"链接: ","source":"来源: twn29004's Blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'twn29004\'s Blog',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-10-30 15:07:34'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112082242974.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">30</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">21</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-video"></i><span> 相册</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('https://picture.zwc365.com/getbing.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">twn29004's Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-video"></i><span> 相册</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">twn29004's Blog</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/twn29004" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:twn29004@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/12/15/new/" title="Attentional PointNet for 3D-Object Detection in Point Clouds论文解读">Attentional PointNet for 3D-Object Detection in Point Clouds论文解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-14T16:00:00.000Z" title="发表于 2021-12-15 00:00:00">2021-12-15</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span></div><div class="content">
代码链接
paper链接
论文总结
这是2019年CVPR的一篇文章，本文提出了一种新的利用循环神经网络来做三维目标检测的方法。并且使用了类似于BERT中讲图像分割成patch的方法来处理大型的点云场景。本文的实验效果一般，速度在kitti排行榜上也很一般，不知道为什么能发CVPR. 下面简单介绍一下本文的主要思想。

作者首先讲点云场景划分为\(12 \times 12\)大小的patch，并将其在\(z\)轴上投影得到一个深度图。使用PointNet来处理点云，使用卷积神经网络来处理深度图，然后讲这两个特征进行相加，这样的话就可以得到关于这个patch的上下文信息。然后就来到了循环定位网络（Recurrent Localization Net）。这个网络的输入包含两个部分，一个是Context Vector，上一个循环神经网络的隐含向量的输出。每个GRU一个分支是输出目标的置信度，另一个一个分支是输出一个目标可能所处的位置以及方向。然后在对应的patch中，仅从坐标变化以及重采样。在经过变化得到的感兴趣区域上计算目标边界框的大小以及位置。
关于GRU迭代的次数，作者 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/12/14/MLCVNet%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="MLCVNet解读">MLCVNet解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-13T16:00:00.000Z" title="发表于 2021-12-14 00:00:00">2021-12-14</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span></div><div class="content">

代码链接
paper链接
论文总结
本文首先提出了三维目标检测中对于一些含有点云数量很少的目标，人类都难以辨别，此外，大部分的网络都是单独的考虑每一个proposal，这也大大加大了网络来辨别的难度。此外，作者通过观察发现，如果能够结合上下文信息的话，我们可能能够更加简单的辨别出所需要的目标。

上图是作者用来展示上下文信息的重要性的。如果单独拿一个目标出来，人类肉眼都难以辨别这个是什么类型的目标，但是如果知道这是一个餐厅的话，有60%的概率能够辨别出来是椅子，如果能够知道这个目标周围有社么的话，有85%的把握知道这是一个椅子，如果既知道是餐厅，又知道是厨房的话，就有90%的把握能够预测出是椅子。
因此，针对上面的现象，作者提出了多个层级的上下文信息提取模块。首先是patch2patch的上下文信息。patch应该指的是原始的点云场景中的一个局部区域。作者文中的解释是，通过相似的patch之间的互补来弥补一些目标点很少的问题。此外，由于votenet中仅单独的考虑每一个proposal，这没有充分的利用proposl中的上下文信息。因此作者还提出了一个objec2o ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/12/11/BANet(Boundary%20aware%20Net)/" title="BANet论文解读">BANet论文解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-10T16:00:00.000Z" title="发表于 2021-12-11 00:00:00">2021-12-11</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span></div><div class="content">
代码链接
paper链接
论文总结

本文首先提出了一个目前二阶段目标检测网络存在的问题，就是第一阶段提出的proposal通常与真实的边界框存在一定的偏移，特别是在距离较远，包含点很少的目标。例如上图中的(a),(c),(d)中提出的proposal.由于偏移的存在，这样的话这些边界框就很难获的目标的边缘信息。此外，现存的refine的网络也没有聚合或者补偿这些边界信息的机制。此外，现存的网络在优化这些proposal的时候，通常是独立的来优化这些proposal，本文中提出了一种将这些proposal建立图神经网络来同时调整以及特征的传播。作者的解释是通过这个图神经网络，使得当前的proposal能够扩大感受野，获得与其相邻的其他proposal的特征，这样的话就能更好的获得目标的边界信息。
此外，由于BEV的表达方式存在着一些问题，比如特征模糊或者放弃了3D结构的上下文信息，因此作者提出了一个新的局部特征聚合的网络来弥补这些损失。
本文中图神经网络的机制:

以两个proposal的中心点为衡量标准，半径r内的proposal之间存在一条边。所有的propos ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/12/11/%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8F%AF%E8%A1%8C%E6%80%A7/" title="霍夫丁不等式证明学习的可行性">霍夫丁不等式证明学习的可行性</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-10T16:00:00.000Z" title="发表于 2021-12-11 00:00:00">2021-12-11</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E7%9F%A5%E8%AF%86%E5%88%86%E4%BA%AB/">知识分享</a></span></div><div class="content">学习的可行性
机器学习基石--学习的可行性 | 吴良超的学习笔记 (wulc.me)
霍夫丁不等式
霍夫丁不等式描述的抽样的数目与模型的误差之间的关系。假如橙色弹珠的真实比例为\(\nu\),模型估计的比率为\(\mu\),样本大小为\(N\)，则对应的霍夫丁不等式为:
\[
P(|\nu - \mu| &lt; \epsilon) \le 2exp(-2 \epsilon^2N)
\]
\(\epsilon\)表示误差允许的范围。
从霍夫丁不等式到机器学习
考虑一个二分类问题，绿色弹珠表示样本标签与我们模型\(h\)的预测值一致，橙色弹珠表示样本标签与模型\(h\)的预测不一致，同时将模型\(h\)在全部弹珠中的分类错误率记为\(E_{out}(h)\)，在训练样本中的分类错误率记为\(E_{in}(h)\)。
霍夫丁不等式描述的就是当模型\(h\)在训练样本上的分类错误率足够小的话，\(E_{in}(h)\)将足够接近\(E_{out}(h)\)。即
\[
P(|E_{in}(h)-P_{out}(h)| &lt; \epsilon) \le 2exp(-2 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/12/08/PCT(Meng%E2%80%94Hao)/" title="Point cloud transformer论文解读">Point cloud transformer论文解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-07T16:00:00.000Z" title="发表于 2021-12-08 00:00:00">2021-12-08</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span></div><div class="content">
代码链接
paper链接
论文总结
本文提出了一种在适用于点云的Transformer结构。根据点云数据的特点进一步改善了Transformer的结构。其主要做了三点改进:

基于坐标的输入嵌入方法
改进的offset-attention方法(想法主要来源于图神经网络)
邻近点嵌入方法

下面依次介绍上述三种改进点以及改进的原因。
首先介绍原始的Transformer结构在点云中的使用。

使用点云的Encoder结构来提取点云的特征。首先使用一个输入嵌入层来转化点云的坐标，就是将三维的点云坐标映射到一个更高维的空间。这一步的目的是使得具有相似语义信息的点云能够在高维空间中更加靠近。文中这一步是使用线性层来完成的。然后将经过转化后的坐标输入到级联的Attention网络中。然后将各个层级的Attention网络的输出拼接起来，再经过一个线性层以得到一个逐点的特征，然后使用一个Max Pooling或者Mean Pooling操作来获得一个全局的特征。这样我们就可以使用全局的特征来进行点云的分类了。如果是其他任务的话，可以把全局特征和前面逐点的特征进行拼接，在 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/12/07/Pointformer/" title="3D ObJect Detection with Pointformer">3D ObJect Detection with Pointformer</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-06T16:00:00.000Z" title="发表于 2021-12-07 00:00:00">2021-12-07</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span></div><div class="content">
代码链接
paper链接

论文总结
作者提出了一种在3D目标检测任务中的一种基于纯Transformer结构的骨干网络。并在室内，室外的数据集上验证了所提方法的有效性。感觉作者主要是改进了PointNet++的Set Abstraction层。其网络的总体流程如下:


图1-Pointformer结构



图2-PointNet2结构

作者主要改进的是Pointformers部分.作者使用了类似PointNet2中的结构设计主要改进了Set Abstraction层。对于Pointformer中的Local Transformer部分的结构如下图所示:


图3-Pointformer结构

和Pointnet2一样，首先对输入点云进行采样和聚合。采样使用的是FPS采样方法，聚合使用的是球形聚合(即聚合距离点距离r以内的点)。这样就形成了以采样点为中心的局部区域。由于Transformer中还需要一个位置映射。因此，相比于PointNet2，Pointfromer增加了一个位置操作。然后讲聚合后的特征以及位置嵌入送入到Transforme ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/12/02/RPN%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/" title="RPN网络总结">RPN网络总结</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-01T16:00:00.000Z" title="发表于 2021-12-02 00:00:00">2021-12-02</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></span></div><div class="content">常见的RPN网络
Faster-RCNN中的RPN网络

在Backbone生成的特征图中，使用大小为\(3\times 3\)的卷积处理特征图，针对每一个中心点生成一个256维的向量。特征图可以理解为原图的一种缩小版。 使用\(3\times3\)的卷积处理特征图可以对应到原图中的一个区域。然后RPN网络的目的就是在原图中的各个区域放置anchors。然后根据提取的特征判断这些anchor是否合理以及之后对这些anchor进行调整。
针对特征图中的每一个中心点，使用\(3\times3\)的卷积来提取特征图的特征，生成一个256-D的向量。这个256-D的向量可以理解为对应于原始图像中的某一个区域。然后使用一些全连接层来判断这些anchor是背景还是前景，以及这些anchor距离目标中心点的偏移。
上述步骤处理完成之后，我们就在提取的特征图上的每一个点都获得了一组anchor,及其是否是前景点还是背景点，以及其相对Ground truth的偏移。然后我们需要proposal layer网络来生成proposal了。其基本步骤如下：

生成anchors. 根据前面的RP ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/11/29/CT3D%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/" title="CT3D论文">CT3D论文</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-11-28T16:00:00.000Z" title="发表于 2021-11-29 00:00:00">2021-11-29</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span></div><div class="content">
代码链接
paper链接
论文总结
本文提出了一种目前二阶段的目标检测算法不能很好的提取proposal中的特征。本文提出了一种基于通道层面的self-attention结构来提高网络对于proposal中点的特征的提取能力。
下面简单介绍一下网络的处理流程:

与传统的二阶段目标检测器一样，首先使用一个backbone提取点样场景的特征，然后使用RPN网络生成proposal。注意，这里生成的proposal一个三维的边界框。文中为了能够更好的提取其周围点云的特征，将这个三维边界框转化成了一个不限制高度的圆柱体。圆柱体的直径是底边对角线长度的一定倍数。然后在生成的圆柱体中采样256个点，根据这些点来提取proposal的特征。文中使用了各个点点对原始的三维边界框(就是proposal提出的)的八个角点来计算相对位置作为点的特征的一部分。proposal中的原始特征可以表示为\([\bigtriangleup p_i^c, \bigtriangleup p_i^1, ..., \bigtriangleup p_i^8, f_i^r]\),其中\(\bigtriangle ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/11/27/RPVNet/" title="RPVNet解读">RPVNet解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-11-26T16:00:00.000Z" title="发表于 2021-11-27 00:00:00">2021-11-27</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span></div><div class="content">
代码链接
RPVNet: A Deep and Efficient Range-Point-Voxel Fusion Network for LiDAR Point Cloud Segmentation (arxiv.org)
论文总结
本文实现了一种大场景下的点云语义分割网络，并在SemanticKITTI数据集上实现了1st的结果。其主要通过一种融合的方法来实现。不同于以往的使用基于点，基于体素和基于深度图(Range Image)的方法.但是这些方法都有一定的缺点。之前融合的方法也仅是融合其中的两类。本文提出了一种融合三类数据的网络。网络的主要结构如下:

网络主要分为三个分支，使用了经典的Encoder和Decoder的结构。三个分支分别是基于体素的，基于点云的和基于深度图的。分别使用对应的网络提取各个分支的特征，然后作者使用了点这个分支来作为中间节点，来融合不同来源的数据。不同特征进行融合的算法如下图所示:

将其他特征映射到基于点的表示的话，可以使用最近邻插值或者三线性插值或者双线性插值的方法。以基于深度图到基于点的表示为例:通过计算该点在深度图上的周围的 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/11/27/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E4%B9%A0/" title="贝叶斯学习">贝叶斯学习</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-11-26T16:00:00.000Z" title="发表于 2021-11-27 00:00:00">2021-11-27</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E7%9F%A5%E8%AF%86%E5%88%86%E4%BA%AB/">知识分享</a></span></div><div class="content">贝叶斯理论
计算后验概率
\[
P(h|D)=\frac{P(D|h)p(h)}{p(D)}
\]
其中，\(P(D|h)\)是根据数据观察到的条件概率，\(p(h)\)是先验概率。我们要做的就是在假设空间中找到具有最大后验概率的假设。那么就有:
\[
h_{MAP}= arg max_{h \in H}P(h|D)=argmax_{h \in H} \frac{P(D|h)p(h)}{p(D)}\\=arg max_{h \in H}P(D|h)p(h)
\]
如果每个假设出现的概率相等，等上述问题退化为\(h_{ML}=argmax_{h \in H}P(D|h)\),这个就是极大似然假设。上面那个是极大后验假设。
使用极大似然假设进行癌症诊断的例子：

两个假设：1) 病人有癌症，2) 病人没有癌症
两种可能的测试输出: 1) positive,记为+ 2) negative,记为-
先验知识：P(cancer) = 0.008 P(not cancer)=0.992 P(+|cancer)=0.98 P(- |cancer)=0.02
P(- |n ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/2/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/#content-inner">2</a><span class="page-number current">3</span></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112082242974.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">twn29004</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">30</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">21</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/twn29004"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/twn29004" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:twn29004@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is twn29004's Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/10/30/loss/" title="三维目标检测中常用Loss的分析">三维目标检测中常用Loss的分析</a><time datetime="2022-10-29T16:00:00.000Z" title="发表于 2022-10-30 00:00:00">2022-10-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/07/05/add-user/" title="实验室服务器新建用户">实验室服务器新建用户</a><time datetime="2022-07-04T16:00:00.000Z" title="发表于 2022-07-05 00:00:00">2022-07-05</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/05/31/PointTransformer%E7%B3%BB%E5%88%97/" title="PointTransformer系列">PointTransformer系列</a><time datetime="2022-05-30T16:00:00.000Z" title="发表于 2022-05-31 00:00:00">2022-05-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/05/24/DETR%E7%B3%BB%E5%88%97/" title="DETR系列论文解读">DETR系列论文解读</a><time datetime="2022-05-23T16:00:00.000Z" title="发表于 2022-05-24 00:00:00">2022-05-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/05/17/DVF/" title="DVF论文解读">DVF论文解读</a><time datetime="2022-05-16T16:00:00.000Z" title="发表于 2022-05-17 00:00:00">2022-05-17</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            <a class="card-more-btn" href="/categories/" title="查看更多">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E4%BD%BF%E7%94%A8%E6%8A%80%E8%83%BD/"><span class="card-category-list-name">使用技能</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5/"><span class="card-category-list-name">参考链接</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E7%9F%A5%E8%AF%86%E5%88%86%E4%BA%AB/"><span class="card-category-list-name">知识分享</span><span class="card-category-list-count">4</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"><span class="card-category-list-name">知识总结</span><span class="card-category-list-count">2</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/2D-Object-Detection/" style="font-size: 1.3em; color: #99a1ac">2D Object Detection</a> <a href="/tags/2D-Object-Detection/" style="font-size: 1.1em; color: #999">2D Object-Detection</a> <a href="/tags/3D-Object-Detect-Graph-Network/" style="font-size: 1.1em; color: #999">3D Object Detect, Graph Network</a> <a href="/tags/3D-Object-Detection/" style="font-size: 1.5em; color: #99a9bf">3D Object Detection</a> <a href="/tags/3D-Loss/" style="font-size: 1.1em; color: #999">3D, Loss</a> <a href="/tags/3D%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 1.3em; color: #99a1ac">3D目标检测</a> <a href="/tags/Context-information-self-Attenion/" style="font-size: 1.1em; color: #999">Context information, self-Attenion</a> <a href="/tags/Fusion/" style="font-size: 1.1em; color: #999">Fusion</a> <a href="/tags/Instance-Segment/" style="font-size: 1.1em; color: #999">Instance Segment</a> <a href="/tags/Linux/" style="font-size: 1.1em; color: #999">Linux</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/10/"><span class="card-archive-list-date">十月 2022</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/07/"><span class="card-archive-list-date">七月 2022</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/05/"><span class="card-archive-list-date">五月 2022</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/04/"><span class="card-archive-list-date">四月 2022</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/02/"><span class="card-archive-list-date">二月 2022</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/01/"><span class="card-archive-list-date">一月 2022</span><span class="card-archive-list-count">8</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/12/"><span class="card-archive-list-date">十二月 2021</span><span class="card-archive-list-count">11</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/11/"><span class="card-archive-list-date">十一月 2021</span><span class="card-archive-list-count">3</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">30</div></div><div class="webinfo-item"><div class="item-name">已运行时间 :</div><div class="item-count" id="runtimeshow" data-publishDate="2021-11-26T16:00:00.000Z"></div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-10-30T07:07:33.848Z"></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2022 By twn29004</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">保持热爱，奔赴山海</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function subtitleType () {
  fetch('https://v1.hitokoto.cn')
    .then(response => response.json())
    .then(data => {
      if (true) {
        var from = '出自 ' + data.from
        var sub = "保持热爱，奔赴山海".length == 0 ? new Array() : "保持热爱，奔赴山海".split(',')
        var both = sub.unshift(data.hitokoto, from)
        var typed = new Typed('#subtitle', {
          strings: sub,
          startDelay: 300,
          typeSpeed: 150,
          loop: false,
          backSpeed: 50,
        })
      } else {
        document.getElementById('subtitle').innerHTML = data.hitokoto
      }
    })
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}
</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>
<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>twn29004's Blog</title><meta name="author" content="twn29004"><meta name="copyright" content="twn29004"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="twn29004&#39;s Blog">
<meta property="og:url" content="http://twn29004.top/page/2/index.html">
<meta property="og:site_name" content="twn29004&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112082242974.jpeg">
<meta property="article:author" content="twn29004">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112082242974.jpeg"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://twn29004.top/page/2/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?da945d048bc901ec4ee07f4643119577";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: twn29004","link":"链接: ","source":"来源: twn29004's Blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'twn29004\'s Blog',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-04-24 19:51:19'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112082242974.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">24</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-video"></i><span> 相册</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('https://picture.zwc365.com/getbing.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">twn29004's Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-video"></i><span> 相册</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">twn29004's Blog</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/twn29004" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:twn29004@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/12/30/AFDetV2/" title="AFDetV2论文解读">AFDetV2论文解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-29T16:00:00.000Z" title="发表于 2021-12-30 00:00:00">2021-12-30</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span></div><div class="content">
代码链接
paper链接
个人博客
问题

本文提出了一种单阶段的三维目标检测算法，并在文中分析了二阶段三维目标检测算法的不必要性。其所提算法在waymo实时目标检测竞赛中取得了第一的成绩。其性能超过了所有单阶段和多阶段的目标检测算法。
作者首先分析了二阶段目标检测算法主要有两个作用，一是二阶段中逐点的特征可能能够在一定程度上恢复因为前期的体素化，卷积的步长和感受野的缺乏带来的信息损失。另一个原因是因为分类和回归这两个独立的分支可能在一定程度上不能对齐，因此需要一个二阶段的网络来进行调整。
对于逐点的特征能够在一定程度上恢复因一系列操作带来的信息损失，作者引用了一些论文中的说明，当基于体素的特征能够实现和基于点的特征相同的位置精度。对于任务不对齐的问题，作者通过实验发现，第一阶段提出的边界框已经非常精确了，第二阶段对于性能的提升主要集中于分类的置信度上。换句话说就是第二阶段可能对定位精度没有帮助。
上述观察与使用二阶段网络中的第二个理由是相符的。即一阶段中独立的分类和定位任务可能存在不对齐的情况，因此使用二阶段的网络来对定位精度高的anchor的分类精度进行调整。 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/12/24/tood/" title="TOOD论文解读">TOOD论文解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-23T16:00:00.000Z" title="发表于 2021-12-24 00:00:00">2021-12-24</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span></div><div class="content">
代码链接
paper链接
个人博客
问题
本文首先提出了一个目前一阶目标检测器存在的普遍问题就是在head部分将分类和定位这两个任务并行的来做了。这样的话就存在两个任务之间不对齐的问题。因为两个任务是的目标不一样。分类任务更加关注目标的显著的，关键的特征。而定位任务更加关注图像的边界特征。这就导致当使用两个独立的分支来进行预测的时候，会导致一定程度上的结果的不能对齐。

如上图所示，第一张中的result列，绿色和红色的方块表示的是在定位任务和分类任务中生成的最有的anchor,白色箭头表明的是最优的anchor相对目标中心偏移。从上述中我们可以看出，第一行中的分类任务红色anchor的最优的anchor虽然分类出了dining table，但是其最优的anchor确是在piza上。而最优的定位任务的anchor，其分类的分数又很低。这就是两个任务没有对齐的表现。就是说分类性能好的anchor，其定位的精度差。定位精度高的anchor,其分类性能差。
此外，目前对于anchor的分配策略也是任务无关的。例如上图中的，由于最优的定位anchor不位于目标的中心点，因此他 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/12/21/BtcNet/" title="BtcNet论文解读">BtcNet论文解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-20T16:00:00.000Z" title="发表于 2021-12-21 00:00:00">2021-12-21</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span></div><div class="content">
代码链接
paper链接
提出的问题
作者首先指出LiDAR帧其实不是严格意义上的3D结构，而是一个2.5D的结构。因为LiDAR通常只能获得目标靠近传感器那部分的结构特征，远离传感器部分的结构通常因为遮挡难以获得。作者将这个问题称为shape miss.作者在引言中回答了关于shape miss的两个重要问题:

点云中造成shape miss的主要原因是什么。
在三维目标检测中shape miss带来的影响。

造成shape miss主要由三个原因:

外部遮挡。前方物体挡住了后面的物体，使得传感器难以感知到后面的物体。
信号丢失。由于目标的材质或者传感器的原因，一部分传感器信号丢失，使得传感器难以感知这个区域
自身遮挡。物体自身的靠近传感器的部分遮挡住了远离传感器的部分。


shape miss对三维目标检测带来的影响:

方法概述
\(X\)表示预测的边界框的中心点，\(D\)表示的是边界框的维度，\(S_{ob}\)表示的是能够观测到的目标的形状，\(S_{oc}\)表示被遮挡的目标的形状。\(\theta\)表示的是检测器的参数， ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/12/20/GPU-tips/" title="关于服务器GPU使用的一些注意事项">关于服务器GPU使用的一些注意事项</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-19T16:00:00.000Z" title="发表于 2021-12-20 00:00:00">2021-12-20</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E7%9F%A5%E8%AF%86%E5%88%86%E4%BA%AB/">知识分享</a></span></div><div class="content">关于GPU
nvidia-smi命令

1表示的是显存的占用率，可以理解为电脑内存，手机运行内存的占用率。2表示的是显卡利用率，可以理解为电脑CPU的占用率。3表示的是占用显卡的进程的相关信息。
关于显卡利用率的问题
有时候会遇到程序占着显存，但是显卡利用率为0的情况。这个时候可以从两个方面进行分析:

查看进程是否挂起。查看方法ls -l \proc\PID。举个例子，查看上图中PID为41732的程序的相关信息.使用以下命令ls -l \proc\41732

可以通过cwd和exe查看相关进程的信息。如果出现该进程deleted的情况，说明该进程被挂起，可以私信对应的同学询问具体情况。
tips: 在终止程序运行时，因使用快捷键ctrl + C。不是使用ctrl+Z。后者是将程序挂起。不清楚的同学可参考参考链接
nvidia-smi命令没有显示进程占用显存，但是显存占用率依然很高，且显卡利用率为0。这个时候可能是出现显存泄露的问题。处理方法可参考参考链接
不是上述两种情况，即程序正常再跑，但是显卡利用率很低，且出现一会高一会低的情况，显存也正常。这个时候可 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/12/15/new/" title="Attentional PointNet for 3D-Object Detection in Point Clouds论文解读">Attentional PointNet for 3D-Object Detection in Point Clouds论文解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-14T16:00:00.000Z" title="发表于 2021-12-15 00:00:00">2021-12-15</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span></div><div class="content">
代码链接
paper链接
论文总结
这是2019年CVPR的一篇文章，本文提出了一种新的利用循环神经网络来做三维目标检测的方法。并且使用了类似于BERT中讲图像分割成patch的方法来处理大型的点云场景。本文的实验效果一般，速度在kitti排行榜上也很一般，不知道为什么能发CVPR. 下面简单介绍一下本文的主要思想。

作者首先讲点云场景划分为\(12 \times 12\)大小的patch，并将其在\(z\)轴上投影得到一个深度图。使用PointNet来处理点云，使用卷积神经网络来处理深度图，然后讲这两个特征进行相加，这样的话就可以得到关于这个patch的上下文信息。然后就来到了循环定位网络（Recurrent Localization Net）。这个网络的输入包含两个部分，一个是Context Vector，上一个循环神经网络的隐含向量的输出。每个GRU一个分支是输出目标的置信度，另一个一个分支是输出一个目标可能所处的位置以及方向。然后在对应的patch中，仅从坐标变化以及重采样。在经过变化得到的感兴趣区域上计算目标边界框的大小以及位置。
关于GRU迭代的次数，作者 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/12/14/MLCVNet%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="MLCVNet解读">MLCVNet解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-13T16:00:00.000Z" title="发表于 2021-12-14 00:00:00">2021-12-14</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span></div><div class="content">

代码链接
paper链接
论文总结
本文首先提出了三维目标检测中对于一些含有点云数量很少的目标，人类都难以辨别，此外，大部分的网络都是单独的考虑每一个proposal，这也大大加大了网络来辨别的难度。此外，作者通过观察发现，如果能够结合上下文信息的话，我们可能能够更加简单的辨别出所需要的目标。

上图是作者用来展示上下文信息的重要性的。如果单独拿一个目标出来，人类肉眼都难以辨别这个是什么类型的目标，但是如果知道这是一个餐厅的话，有60%的概率能够辨别出来是椅子，如果能够知道这个目标周围有社么的话，有85%的把握知道这是一个椅子，如果既知道是餐厅，又知道是厨房的话，就有90%的把握能够预测出是椅子。
因此，针对上面的现象，作者提出了多个层级的上下文信息提取模块。首先是patch2patch的上下文信息。patch应该指的是原始的点云场景中的一个局部区域。作者文中的解释是，通过相似的patch之间的互补来弥补一些目标点很少的问题。此外，由于votenet中仅单独的考虑每一个proposal，这没有充分的利用proposl中的上下文信息。因此作者还提出了一个objec2o ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/12/11/BANet(Boundary%20aware%20Net)/" title="BANet论文解读">BANet论文解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-10T16:00:00.000Z" title="发表于 2021-12-11 00:00:00">2021-12-11</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span></div><div class="content">
代码链接
paper链接
论文总结

本文首先提出了一个目前二阶段目标检测网络存在的问题，就是第一阶段提出的proposal通常与真实的边界框存在一定的偏移，特别是在距离较远，包含点很少的目标。例如上图中的(a),(c),(d)中提出的proposal.由于偏移的存在，这样的话这些边界框就很难获的目标的边缘信息。此外，现存的refine的网络也没有聚合或者补偿这些边界信息的机制。此外，现存的网络在优化这些proposal的时候，通常是独立的来优化这些proposal，本文中提出了一种将这些proposal建立图神经网络来同时调整以及特征的传播。作者的解释是通过这个图神经网络，使得当前的proposal能够扩大感受野，获得与其相邻的其他proposal的特征，这样的话就能更好的获得目标的边界信息。
此外，由于BEV的表达方式存在着一些问题，比如特征模糊或者放弃了3D结构的上下文信息，因此作者提出了一个新的局部特征聚合的网络来弥补这些损失。
本文中图神经网络的机制:

以两个proposal的中心点为衡量标准，半径r内的proposal之间存在一条边。所有的propos ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/12/11/%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8F%AF%E8%A1%8C%E6%80%A7/" title="霍夫丁不等式证明学习的可行性">霍夫丁不等式证明学习的可行性</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-10T16:00:00.000Z" title="发表于 2021-12-11 00:00:00">2021-12-11</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E7%9F%A5%E8%AF%86%E5%88%86%E4%BA%AB/">知识分享</a></span></div><div class="content">学习的可行性
机器学习基石--学习的可行性 | 吴良超的学习笔记 (wulc.me)
霍夫丁不等式
霍夫丁不等式描述的抽样的数目与模型的误差之间的关系。假如橙色弹珠的真实比例为\(\nu\),模型估计的比率为\(\mu\),样本大小为\(N\)，则对应的霍夫丁不等式为:
\[
P(|\nu - \mu| &lt; \epsilon) \le 2exp(-2 \epsilon^2N)
\]
\(\epsilon\)表示误差允许的范围。
从霍夫丁不等式到机器学习
考虑一个二分类问题，绿色弹珠表示样本标签与我们模型\(h\)的预测值一致，橙色弹珠表示样本标签与模型\(h\)的预测不一致，同时将模型\(h\)在全部弹珠中的分类错误率记为\(E_{out}(h)\)，在训练样本中的分类错误率记为\(E_{in}(h)\)。
霍夫丁不等式描述的就是当模型\(h\)在训练样本上的分类错误率足够小的话，\(E_{in}(h)\)将足够接近\(E_{out}(h)\)。即
\[
P(|E_{in}(h)-P_{out}(h)| &lt; \epsilon) \le 2exp(-2 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/12/08/PCT(Meng%E2%80%94Hao)/" title="Point cloud transformer论文解读">Point cloud transformer论文解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-07T16:00:00.000Z" title="发表于 2021-12-08 00:00:00">2021-12-08</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span></div><div class="content">
代码链接
paper链接
论文总结
本文提出了一种在适用于点云的Transformer结构。根据点云数据的特点进一步改善了Transformer的结构。其主要做了三点改进:

基于坐标的输入嵌入方法
改进的offset-attention方法(想法主要来源于图神经网络)
邻近点嵌入方法

下面依次介绍上述三种改进点以及改进的原因。
首先介绍原始的Transformer结构在点云中的使用。

使用点云的Encoder结构来提取点云的特征。首先使用一个输入嵌入层来转化点云的坐标，就是将三维的点云坐标映射到一个更高维的空间。这一步的目的是使得具有相似语义信息的点云能够在高维空间中更加靠近。文中这一步是使用线性层来完成的。然后将经过转化后的坐标输入到级联的Attention网络中。然后将各个层级的Attention网络的输出拼接起来，再经过一个线性层以得到一个逐点的特征，然后使用一个Max Pooling或者Mean Pooling操作来获得一个全局的特征。这样我们就可以使用全局的特征来进行点云的分类了。如果是其他任务的话，可以把全局特征和前面逐点的特征进行拼接，在 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/12/07/Pointformer/" title="3D ObJect Detection with Pointformer">3D ObJect Detection with Pointformer</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-06T16:00:00.000Z" title="发表于 2021-12-07 00:00:00">2021-12-07</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span></div><div class="content">
代码链接
paper链接

论文总结
作者提出了一种在3D目标检测任务中的一种基于纯Transformer结构的骨干网络。并在室内，室外的数据集上验证了所提方法的有效性。感觉作者主要是改进了PointNet++的Set Abstraction层。其网络的总体流程如下:


图1-Pointformer结构



图2-PointNet2结构

作者主要改进的是Pointformers部分.作者使用了类似PointNet2中的结构设计主要改进了Set Abstraction层。对于Pointformer中的Local Transformer部分的结构如下图所示:


图3-Pointformer结构

和Pointnet2一样，首先对输入点云进行采样和聚合。采样使用的是FPS采样方法，聚合使用的是球形聚合(即聚合距离点距离r以内的点)。这样就形成了以采样点为中心的局部区域。由于Transformer中还需要一个位置映射。因此，相比于PointNet2，Pointfromer增加了一个位置操作。然后讲聚合后的特征以及位置嵌入送入到Transforme ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/#content-inner">3</a><a class="extend next" rel="next" href="/page/3/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112082242974.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">twn29004</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">24</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/twn29004"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/twn29004" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:twn29004@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is twn29004's Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/02/27/mmvirtualpioint/" title="Multimodal Virtual Point 3D Detection论文解读">Multimodal Virtual Point 3D Detection论文解读</a><time datetime="2022-02-26T16:00:00.000Z" title="发表于 2022-02-27 00:00:00">2022-02-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/02/26/2-17%E8%B0%83%E7%A0%94/" title="无题">无题</a><time datetime="2022-02-26T00:49:09.966Z" title="发表于 2022-02-26 08:49:09">2022-02-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/01/14/Faster-RCNN/" title="Faster-RCNN论文解读">Faster-RCNN论文解读</a><time datetime="2022-01-13T16:00:00.000Z" title="发表于 2022-01-14 00:00:00">2022-01-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/01/13/3D_IoU_Net/" title="3D IoU-Net论文解读">3D IoU-Net论文解读</a><time datetime="2022-01-12T16:00:00.000Z" title="发表于 2022-01-13 00:00:00">2022-01-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/01/12/YOLOF/" title="YOLOF论文解读">YOLOF论文解读</a><time datetime="2022-01-11T16:00:00.000Z" title="发表于 2022-01-12 00:00:00">2022-01-12</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5/"><span class="card-category-list-name">参考链接</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E7%9F%A5%E8%AF%86%E5%88%86%E4%BA%AB/"><span class="card-category-list-name">知识分享</span><span class="card-category-list-count">4</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"><span class="card-category-list-name">知识总结</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"><span class="card-category-list-name">论文分享</span><span class="card-category-list-count">16</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/2D-Object-Detection/" style="font-size: 1.3em; color: #99a1ac">2D Object Detection</a> <a href="/tags/2D-Object-Detection/" style="font-size: 1.1em; color: #999">2D Object-Detection</a> <a href="/tags/3D-Object-Detect-Graph-Network/" style="font-size: 1.1em; color: #999">3D Object Detect, Graph Network</a> <a href="/tags/3D-Object-Detection/" style="font-size: 1.5em; color: #99a9bf">3D Object Detection</a> <a href="/tags/3D%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 1.3em; color: #99a1ac">3D目标检测</a> <a href="/tags/Context-information-self-Attenion/" style="font-size: 1.1em; color: #999">Context information, self-Attenion</a> <a href="/tags/Fusion/" style="font-size: 1.1em; color: #999">Fusion</a> <a href="/tags/Instance-Segment/" style="font-size: 1.1em; color: #999">Instance Segment</a> <a href="/tags/Object-Detection/" style="font-size: 1.5em; color: #99a9bf">Object Detection</a> <a href="/tags/Object-Detection-2D-Object-Detection/" style="font-size: 1.1em; color: #999">Object Detection, 2D Object Detection</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/02/"><span class="card-archive-list-date">二月 2022</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/01/"><span class="card-archive-list-date">一月 2022</span><span class="card-archive-list-count">8</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/12/"><span class="card-archive-list-date">十二月 2021</span><span class="card-archive-list-count">11</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/11/"><span class="card-archive-list-date">十一月 2021</span><span class="card-archive-list-count">3</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">24</div></div><div class="webinfo-item"><div class="item-name">已运行时间 :</div><div class="item-count" id="runtimeshow" data-publishDate="2021-11-26T16:00:00.000Z"></div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-04-24T11:51:19.188Z"></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2022 By twn29004</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">保持热爱，奔赴山海</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function subtitleType () {
  fetch('https://v1.hitokoto.cn')
    .then(response => response.json())
    .then(data => {
      if (true) {
        var from = '出自 ' + data.from
        var sub = "保持热爱，奔赴山海".length == 0 ? new Array() : "保持热爱，奔赴山海".split(',')
        var both = sub.unshift(data.hitokoto, from)
        var typed = new Typed('#subtitle', {
          strings: sub,
          startDelay: 300,
          typeSpeed: 150,
          loop: false,
          backSpeed: 50,
        })
      } else {
        document.getElementById('subtitle').innerHTML = data.hitokoto
      }
    })
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}
</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>
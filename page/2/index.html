<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>twn29004's Blog</title><meta name="author" content="twn29004"><meta name="copyright" content="twn29004"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="twn29004&#39;s Blog">
<meta property="og:url" content="http://twn29004.top/page/2/index.html">
<meta property="og:site_name" content="twn29004&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112082242974.jpeg">
<meta property="article:author" content="twn29004">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112082242974.jpeg"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://twn29004.top/page/2/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?da945d048bc901ec4ee07f4643119577";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: twn29004","link":"链接: ","source":"来源: twn29004's Blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'twn29004\'s Blog',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-01-19 21:11:27'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112082242974.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">22</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-video"></i><span> 相册</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('https://picture.zwc365.com/getbing.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">twn29004's Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-video"></i><span> 相册</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">twn29004's Blog</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/twn29004" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:twn29004@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/12/21/BtcNet/" title="BtcNet论文解读">     <img class="post_bg" src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112211526344.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="BtcNet论文解读"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/21/BtcNet/" title="BtcNet论文解读">BtcNet论文解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-20T16:00:00.000Z" title="发表于 2021-12-21 00:00:00">2021-12-21</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2021/12/21/BtcNet/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2021/12/21/BtcNet/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">
代码链接
paper链接
提出的问题
作者首先指出LiDAR帧其实不是严格意义上的3D结构，而是一个2.5D的结构。因为LiDAR通常只能获得目标靠近传感器那部分的结构特征，远离传感器部分的结构通常因为遮挡难以获得。作者将这个问题称为shape miss.作者在引言中回答了关于shape miss的两个重要问题:

点云中造成shape miss的主要原因是什么。
在三维目标检测中shape miss带来的影响。

造成shape miss主要由三个原因:

外部遮挡。前方物体挡住了后面的物体，使得传感器难以感知到后面的物体。
信号丢失。由于目标的材质或者传感器的原因，一部分传感器信号丢失，使得传感器难以感知这个区域
自身遮挡。物体自身的靠近传感器的部分遮挡住了远离传感器的部分。


shape miss对三维目标检测带来的影响:

方法概述
\(X\)表示预测的边界框的中心点，\(D\)表示的是边界框的维度，\(S_{ob}\)表示的是能够观测到的目标的形状，\(S_{oc}\)表示被遮挡的目标的形状。\(\theta\)表示的是检测器的参数， ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/12/20/GPU-tips/" title="关于服务器GPU使用的一些注意事项">     <img class="post_bg" src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112202022002.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="关于服务器GPU使用的一些注意事项"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/20/GPU-tips/" title="关于服务器GPU使用的一些注意事项">关于服务器GPU使用的一些注意事项</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-19T16:00:00.000Z" title="发表于 2021-12-20 00:00:00">2021-12-20</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E7%9F%A5%E8%AF%86%E5%88%86%E4%BA%AB/">知识分享</a></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2021/12/20/GPU-tips/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2021/12/20/GPU-tips/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">关于GPU
nvidia-smi命令

1表示的是显存的占用率，可以理解为电脑内存，手机运行内存的占用率。2表示的是显卡利用率，可以理解为电脑CPU的占用率。3表示的是占用显卡的进程的相关信息。
关于显卡利用率的问题
有时候会遇到程序占着显存，但是显卡利用率为0的情况。这个时候可以从两个方面进行分析:

查看进程是否挂起。查看方法ls -l \proc\PID。举个例子，查看上图中PID为41732的程序的相关信息.使用以下命令ls -l \proc\41732

可以通过cwd和exe查看相关进程的信息。如果出现该进程deleted的情况，说明该进程被挂起，可以私信对应的同学询问具体情况。
tips: 在终止程序运行时，因使用快捷键ctrl + C。不是使用ctrl+Z。后者是将程序挂起。不清楚的同学可参考参考链接
nvidia-smi命令没有显示进程占用显存，但是显存占用率依然很高，且显卡利用率为0。这个时候可能是出现显存泄露的问题。处理方法可参考参考链接
不是上述两种情况，即程序正常再跑，但是显卡利用率很低，且出现一会高一会低的情况，显存也正常。这个时候可 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/12/15/new/" title="Attentional PointNet for 3D-Object Detection in Point Clouds论文解读">     <img class="post_bg" src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112152159932.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Attentional PointNet for 3D-Object Detection in Point Clouds论文解读"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/15/new/" title="Attentional PointNet for 3D-Object Detection in Point Clouds论文解读">Attentional PointNet for 3D-Object Detection in Point Clouds论文解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-14T16:00:00.000Z" title="发表于 2021-12-15 00:00:00">2021-12-15</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2021/12/15/new/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2021/12/15/new/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">
代码链接
paper链接
论文总结
这是2019年CVPR的一篇文章，本文提出了一种新的利用循环神经网络来做三维目标检测的方法。并且使用了类似于BERT中讲图像分割成patch的方法来处理大型的点云场景。本文的实验效果一般，速度在kitti排行榜上也很一般，不知道为什么能发CVPR. 下面简单介绍一下本文的主要思想。

作者首先讲点云场景划分为\(12 \times 12\)大小的patch，并将其在\(z\)轴上投影得到一个深度图。使用PointNet来处理点云，使用卷积神经网络来处理深度图，然后讲这两个特征进行相加，这样的话就可以得到关于这个patch的上下文信息。然后就来到了循环定位网络（Recurrent Localization Net）。这个网络的输入包含两个部分，一个是Context Vector，上一个循环神经网络的隐含向量的输出。每个GRU一个分支是输出目标的置信度，另一个一个分支是输出一个目标可能所处的位置以及方向。然后在对应的patch中，仅从坐标变化以及重采样。在经过变化得到的感兴趣区域上计算目标边界框的大小以及位置。
关于GRU迭代的次数，作者 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/12/14/MLCVNet%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="MLCVNet解读">     <img class="post_bg" src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112141101579.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MLCVNet解读"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/14/MLCVNet%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="MLCVNet解读">MLCVNet解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-13T16:00:00.000Z" title="发表于 2021-12-14 00:00:00">2021-12-14</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2021/12/14/MLCVNet%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2021/12/14/MLCVNet%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">

代码链接
paper链接
论文总结
本文首先提出了三维目标检测中对于一些含有点云数量很少的目标，人类都难以辨别，此外，大部分的网络都是单独的考虑每一个proposal，这也大大加大了网络来辨别的难度。此外，作者通过观察发现，如果能够结合上下文信息的话，我们可能能够更加简单的辨别出所需要的目标。

上图是作者用来展示上下文信息的重要性的。如果单独拿一个目标出来，人类肉眼都难以辨别这个是什么类型的目标，但是如果知道这是一个餐厅的话，有60%的概率能够辨别出来是椅子，如果能够知道这个目标周围有社么的话，有85%的把握知道这是一个椅子，如果既知道是餐厅，又知道是厨房的话，就有90%的把握能够预测出是椅子。
因此，针对上面的现象，作者提出了多个层级的上下文信息提取模块。首先是patch2patch的上下文信息。patch应该指的是原始的点云场景中的一个局部区域。作者文中的解释是，通过相似的patch之间的互补来弥补一些目标点很少的问题。此外，由于votenet中仅单独的考虑每一个proposal，这没有充分的利用proposl中的上下文信息。因此作者还提出了一个objec2o ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/12/11/BANet(Boundary%20aware%20Net)/" title="BANet论文解读">     <img class="post_bg" src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112111609109.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="BANet论文解读"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/11/BANet(Boundary%20aware%20Net)/" title="BANet论文解读">BANet论文解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-10T16:00:00.000Z" title="发表于 2021-12-11 00:00:00">2021-12-11</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2021/12/11/BANet(Boundary%20aware%20Net)/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2021/12/11/BANet(Boundary%20aware%20Net)/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">
代码链接
paper链接
论文总结

本文首先提出了一个目前二阶段目标检测网络存在的问题，就是第一阶段提出的proposal通常与真实的边界框存在一定的偏移，特别是在距离较远，包含点很少的目标。例如上图中的(a),(c),(d)中提出的proposal.由于偏移的存在，这样的话这些边界框就很难获的目标的边缘信息。此外，现存的refine的网络也没有聚合或者补偿这些边界信息的机制。此外，现存的网络在优化这些proposal的时候，通常是独立的来优化这些proposal，本文中提出了一种将这些proposal建立图神经网络来同时调整以及特征的传播。作者的解释是通过这个图神经网络，使得当前的proposal能够扩大感受野，获得与其相邻的其他proposal的特征，这样的话就能更好的获得目标的边界信息。
此外，由于BEV的表达方式存在着一些问题，比如特征模糊或者放弃了3D结构的上下文信息，因此作者提出了一个新的局部特征聚合的网络来弥补这些损失。
本文中图神经网络的机制:

以两个proposal的中心点为衡量标准，半径r内的proposal之间存在一条边。所有的propos ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/12/11/%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8F%AF%E8%A1%8C%E6%80%A7/" title="霍夫丁不等式证明学习的可行性">     <img class="post_bg" src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112111613226.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="霍夫丁不等式证明学习的可行性"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/11/%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8F%AF%E8%A1%8C%E6%80%A7/" title="霍夫丁不等式证明学习的可行性">霍夫丁不等式证明学习的可行性</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-10T16:00:00.000Z" title="发表于 2021-12-11 00:00:00">2021-12-11</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E7%9F%A5%E8%AF%86%E5%88%86%E4%BA%AB/">知识分享</a></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2021/12/11/%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8F%AF%E8%A1%8C%E6%80%A7/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2021/12/11/%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8F%AF%E8%A1%8C%E6%80%A7/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">学习的可行性
机器学习基石--学习的可行性 | 吴良超的学习笔记 (wulc.me)
霍夫丁不等式
霍夫丁不等式描述的抽样的数目与模型的误差之间的关系。假如橙色弹珠的真实比例为\(\nu\),模型估计的比率为\(\mu\),样本大小为\(N\)，则对应的霍夫丁不等式为:
\[
P(|\nu - \mu| &lt; \epsilon) \le 2exp(-2 \epsilon^2N)
\]
\(\epsilon\)表示误差允许的范围。
从霍夫丁不等式到机器学习
考虑一个二分类问题，绿色弹珠表示样本标签与我们模型\(h\)的预测值一致，橙色弹珠表示样本标签与模型\(h\)的预测不一致，同时将模型\(h\)在全部弹珠中的分类错误率记为\(E_{out}(h)\)，在训练样本中的分类错误率记为\(E_{in}(h)\)。
霍夫丁不等式描述的就是当模型\(h\)在训练样本上的分类错误率足够小的话，\(E_{in}(h)\)将足够接近\(E_{out}(h)\)。即
\[
P(|E_{in}(h)-P_{out}(h)| &lt; \epsilon) \le 2exp(-2 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/12/08/PCT(Meng%E2%80%94Hao)/" title="Point cloud transformer论文解读">     <img class="post_bg" src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112081439852.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Point cloud transformer论文解读"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/08/PCT(Meng%E2%80%94Hao)/" title="Point cloud transformer论文解读">Point cloud transformer论文解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-07T16:00:00.000Z" title="发表于 2021-12-08 00:00:00">2021-12-08</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2021/12/08/PCT(Meng%E2%80%94Hao)/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2021/12/08/PCT(Meng%E2%80%94Hao)/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">
代码链接
paper链接
论文总结
本文提出了一种在适用于点云的Transformer结构。根据点云数据的特点进一步改善了Transformer的结构。其主要做了三点改进:

基于坐标的输入嵌入方法
改进的offset-attention方法(想法主要来源于图神经网络)
邻近点嵌入方法

下面依次介绍上述三种改进点以及改进的原因。
首先介绍原始的Transformer结构在点云中的使用。

使用点云的Encoder结构来提取点云的特征。首先使用一个输入嵌入层来转化点云的坐标，就是将三维的点云坐标映射到一个更高维的空间。这一步的目的是使得具有相似语义信息的点云能够在高维空间中更加靠近。文中这一步是使用线性层来完成的。然后将经过转化后的坐标输入到级联的Attention网络中。然后将各个层级的Attention网络的输出拼接起来，再经过一个线性层以得到一个逐点的特征，然后使用一个Max Pooling或者Mean Pooling操作来获得一个全局的特征。这样我们就可以使用全局的特征来进行点云的分类了。如果是其他任务的话，可以把全局特征和前面逐点的特征进行拼接，在 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/12/07/Pointformer/" title="3D ObJect Detection with Pointformer">     <img class="post_bg" src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112081441922.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="3D ObJect Detection with Pointformer"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/07/Pointformer/" title="3D ObJect Detection with Pointformer">3D ObJect Detection with Pointformer</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-06T16:00:00.000Z" title="发表于 2021-12-07 00:00:00">2021-12-07</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2021/12/07/Pointformer/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2021/12/07/Pointformer/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">
代码链接
paper链接

论文总结
作者提出了一种在3D目标检测任务中的一种基于纯Transformer结构的骨干网络。并在室内，室外的数据集上验证了所提方法的有效性。感觉作者主要是改进了PointNet++的Set Abstraction层。其网络的总体流程如下:


图1-Pointformer结构



图2-PointNet2结构

作者主要改进的是Pointformers部分.作者使用了类似PointNet2中的结构设计主要改进了Set Abstraction层。对于Pointformer中的Local Transformer部分的结构如下图所示:


图3-Pointformer结构

和Pointnet2一样，首先对输入点云进行采样和聚合。采样使用的是FPS采样方法，聚合使用的是球形聚合(即聚合距离点距离r以内的点)。这样就形成了以采样点为中心的局部区域。由于Transformer中还需要一个位置映射。因此，相比于PointNet2，Pointfromer增加了一个位置操作。然后讲聚合后的特征以及位置嵌入送入到Transforme ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/12/02/RPN%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/" title="RPN网络总结">     <img class="post_bg" src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest/img/202112022119925.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="RPN网络总结"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/02/RPN%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/" title="RPN网络总结">RPN网络总结</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-01T16:00:00.000Z" title="发表于 2021-12-02 00:00:00">2021-12-02</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">知识总结</a></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2021/12/02/RPN%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2021/12/02/RPN%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">常见的RPN网络
Faster-RCNN中的RPN网络

在Backbone生成的特征图中，使用大小为\(3\times 3\)的卷积处理特征图，针对每一个中心点生成一个256维的向量。特征图可以理解为原图的一种缩小版。 使用\(3\times3\)的卷积处理特征图可以对应到原图中的一个区域。然后RPN网络的目的就是在原图中的各个区域放置anchors。然后根据提取的特征判断这些anchor是否合理以及之后对这些anchor进行调整。
针对特征图中的每一个中心点，使用\(3\times3\)的卷积来提取特征图的特征，生成一个256-D的向量。这个256-D的向量可以理解为对应于原始图像中的某一个区域。然后使用一些全连接层来判断这些anchor是背景还是前景，以及这些anchor距离目标中心点的偏移。
上述步骤处理完成之后，我们就在提取的特征图上的每一个点都获得了一组anchor,及其是否是前景点还是背景点，以及其相对Ground truth的偏移。然后我们需要proposal layer网络来生成proposal了。其基本步骤如下：

生成anchors. 根据前面的RP ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/11/29/CT3D%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/" title="CT3D论文">     <img class="post_bg" src="https://wallpapercave.com/wp/wp1815131.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CT3D论文"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/11/29/CT3D%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/" title="CT3D论文">CT3D论文</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-11-28T16:00:00.000Z" title="发表于 2021-11-29 00:00:00">2021-11-29</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/">论文分享</a></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2021/11/29/CT3D%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2021/11/29/CT3D%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">
代码链接
paper链接
论文总结
本文提出了一种目前二阶段的目标检测算法不能很好的提取proposal中的特征。本文提出了一种基于通道层面的self-attention结构来提高网络对于proposal中点的特征的提取能力。
下面简单介绍一下网络的处理流程:

与传统的二阶段目标检测器一样，首先使用一个backbone提取点样场景的特征，然后使用RPN网络生成proposal。注意，这里生成的proposal一个三维的边界框。文中为了能够更好的提取其周围点云的特征，将这个三维边界框转化成了一个不限制高度的圆柱体。圆柱体的直径是底边对角线长度的一定倍数。然后在生成的圆柱体中采样256个点，根据这些点来提取proposal的特征。文中使用了各个点点对原始的三维边界框(就是proposal提出的)的八个角点来计算相对位置作为点的特征的一部分。proposal中的原始特征可以表示为\([\bigtriangleup p_i^c, \bigtriangleup p_i^1, ..., \bigtriangleup p_i^8, f_i^r]\),其中\(\bigtriangle ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/#content-inner">3</a><a class="extend next" rel="next" href="/page/3/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://cdn.jsdelivr.net/gh/twn2333/my_imgs@latest//img/202112082242974.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">twn29004</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">22</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/twn29004"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/twn29004" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:twn29004@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is twn29004's Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/01/14/Faster-RCNN/" title="Faster-RCNN论文解读"><img src="https://hdwallsource.com/img/2021/7/basketball-hoop-net-wallpaper-76101-78830-hd-wallpapers.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Faster-RCNN论文解读"/></a><div class="content"><a class="title" href="/2022/01/14/Faster-RCNN/" title="Faster-RCNN论文解读">Faster-RCNN论文解读</a><time datetime="2022-01-13T16:00:00.000Z" title="发表于 2022-01-14 00:00:00">2022-01-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/13/3D_IoU_Net/" title="3D IoU-Net论文解读"><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201132038877.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="3D IoU-Net论文解读"/></a><div class="content"><a class="title" href="/2022/01/13/3D_IoU_Net/" title="3D IoU-Net论文解读">3D IoU-Net论文解读</a><time datetime="2022-01-12T16:00:00.000Z" title="发表于 2022-01-13 00:00:00">2022-01-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/12/YOLOF/" title="YOLOF论文解读"><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201132058169.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="YOLOF论文解读"/></a><div class="content"><a class="title" href="/2022/01/12/YOLOF/" title="YOLOF论文解读">YOLOF论文解读</a><time datetime="2022-01-11T16:00:00.000Z" title="发表于 2022-01-12 00:00:00">2022-01-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/09/GSPN/" title="GSPN论文解读"><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201092122985.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GSPN论文解读"/></a><div class="content"><a class="title" href="/2022/01/09/GSPN/" title="GSPN论文解读">GSPN论文解读</a><time datetime="2022-01-08T16:00:00.000Z" title="发表于 2022-01-09 00:00:00">2022-01-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/09/pytorchwithcuda/" title="Pytorch,CUDA联合编程"><img src="https://blog-image-twn29004.oss-cn-chengdu.aliyuncs.com/blog-img/202201091442970.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Pytorch,CUDA联合编程"/></a><div class="content"><a class="title" href="/2022/01/09/pytorchwithcuda/" title="Pytorch,CUDA联合编程">Pytorch,CUDA联合编程</a><time datetime="2022-01-08T16:00:00.000Z" title="发表于 2022-01-09 00:00:00">2022-01-09</time></div></div></div></div><div class="card-widget" id="card-newest-comments"><div class="item-headline"><i class="fas fa-comment-dots"></i><span>最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5/"><span class="card-category-list-name">参考链接</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E7%9F%A5%E8%AF%86%E5%88%86%E4%BA%AB/"><span class="card-category-list-name">知识分享</span><span class="card-category-list-count">4</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"><span class="card-category-list-name">知识总结</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"><span class="card-category-list-name">论文分享</span><span class="card-category-list-count">15</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/2D-Object-Detection/" style="font-size: 1.3em; color: #99a1ac">2D Object Detection</a> <a href="/tags/2D-Object-Detection/" style="font-size: 1.1em; color: #999">2D Object-Detection</a> <a href="/tags/3D-Object-Detect-Graph-Network/" style="font-size: 1.1em; color: #999">3D Object Detect, Graph Network</a> <a href="/tags/3D-Object-Detection/" style="font-size: 1.5em; color: #99a9bf">3D Object Detection</a> <a href="/tags/3D%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 1.3em; color: #99a1ac">3D目标检测</a> <a href="/tags/Context-information-self-Attenion/" style="font-size: 1.1em; color: #999">Context information, self-Attenion</a> <a href="/tags/Instance-Segment/" style="font-size: 1.1em; color: #999">Instance Segment</a> <a href="/tags/Object-Detection/" style="font-size: 1.5em; color: #99a9bf">Object Detection</a> <a href="/tags/Object-Detection-2D-Object-Detection/" style="font-size: 1.1em; color: #999">Object Detection, 2D Object Detection</a> <a href="/tags/Pytorch/" style="font-size: 1.3em; color: #99a1ac">Pytorch</a> <a href="/tags/Segment/" style="font-size: 1.1em; color: #999">Segment</a> <a href="/tags/%E6%8A%80%E5%B7%A7/" style="font-size: 1.1em; color: #999">技巧</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 1.3em; color: #99a1ac">机器学习</a> <a href="/tags/%E7%82%B9%E4%BA%91%E5%88%86%E5%89%B2/" style="font-size: 1.1em; color: #999">点云分割</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/01/"><span class="card-archive-list-date">一月 2022</span><span class="card-archive-list-count">8</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/12/"><span class="card-archive-list-date">十二月 2021</span><span class="card-archive-list-count">11</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/11/"><span class="card-archive-list-date">十一月 2021</span><span class="card-archive-list-count">3</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">22</div></div><div class="webinfo-item"><div class="item-name">已运行时间 :</div><div class="item-count" id="runtimeshow" data-publishDate="2021-11-26T16:00:00.000Z"></div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">30.1k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-01-19T13:11:27.424Z"></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2022 By twn29004</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">保持热爱，奔赴山海</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  function loadValine () {
    function initValine () {
      let initData = {
        el: '#vcomment',
        appId: 'XNyIVrqGTNnQLppz3iWQJhmo-gzGzoHsz',
        appKey: 'ag39ujwjIYVnIUP3YQLCEoCM',
      }
      
      const valine = new Valine(initData)
    }

    if (typeof Valine === 'function') initValine() 
    else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
  }

  window.pjax ? loadValine() : window.addEventListener('load', loadValine)
})()</script><script>function subtitleType () {
  fetch('https://v1.hitokoto.cn')
    .then(response => response.json())
    .then(data => {
      if (true) {
        var from = '出自 ' + data.from
        var sub = "保持热爱，奔赴山海".length == 0 ? new Array() : "保持热爱，奔赴山海".split(',')
        var both = sub.unshift(data.hitokoto, from)
        var typed = new Typed('#subtitle', {
          strings: sub,
          startDelay: 300,
          typeSpeed: 150,
          loop: true,
          backSpeed: 50,
        })
      } else {
        document.getElementById('subtitle').innerHTML = data.hitokoto
      }
    })
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}
</script></div><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.17.0/js/md5.min.js"></script><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getIcon = (icon, mail) => {
    if (icon) return icon
    let defaultIcon = '?d=monsterid'
    let iconUrl = `https://gravatar.loli.net/avatar/${md5(mail.toLowerCase()) + defaultIcon}`
    return iconUrl
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }

        result += `<div class='content'>
        <a class='comment' href='${array[i].url}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const getComment = () => {
    const serverURL = 'https://xnyivrqg.lc-cn-n1-shared.com'

    var settings = {
      "method": "GET",
      "headers": {
        "X-LC-Id": 'XNyIVrqGTNnQLppz3iWQJhmo-gzGzoHsz',
        "X-LC-Key": 'ag39ujwjIYVnIUP3YQLCEoCM',
        "Content-Type": "application/json"
      },
    }

    fetch(`${serverURL}/1.1/classes/Comment?limit=6&order=-createdAt`,settings)
      .then(response => response.json())
      .then(data => {
        const valineArray = data.results.map(function (e) {
          return {
            'avatar': getIcon(e.QQAvatar, e.mail),
            'content': changeContent(e.comment),
            'nick': e.nick,
            'url': e.url + '#' + e.objectId,
            'date': e.updatedAt,
          }
        })
        saveToLocal.set('valine-newest-comments', JSON.stringify(valineArray), 10/(60*24))
        generateHtml(valineArray)
      }).catch(e => {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.innerHTML= "无法获取评论，请确认相关配置是否正确"
      }) 
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('valine-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>